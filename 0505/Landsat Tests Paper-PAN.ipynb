{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "import models_pytorch\n",
    "import losses_pytorch\n",
    "import imageio as io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from skimage.morphology import binary_dilation, binary_erosion\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from sklearn.metrics import average_precision_score\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.functional as FA\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bce_loss(output,y,weight):\n",
    "    epsilon= 1e-7\n",
    "    output = torch.clamp(output, epsilon, 1.-epsilon)\n",
    "    logit_output = torch.log(output/(1.-output))\n",
    "    \n",
    "    loss = (1.-y)*logit_output + (1.+(weight-1.)*y) * (torch.log(1.+torch.exp(-torch.abs(logit_output))) + torch.maximum(-logit_output,torch.tensor(0.).cuda()))\n",
    "    return torch.sum(loss)/torch.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(output,y,weight):\n",
    "    smooth = 1.\n",
    "    w,m1,m2 = weight*weight, y, output\n",
    "    intersection = (m1*m2)\n",
    "    score = (2.*torch.sum(w*intersection)+smooth)/(torch.sum(w*m1)+torch.sum(w*m2)+smooth)\n",
    "    loss  = 1.-torch.sum(score)\n",
    "    return loss\n",
    "\n",
    "def iou_loss(y_pred, y_true, weight):\n",
    "    weight = weight*weight\n",
    "    intersection = y_true * y_pred\n",
    "    not_true     = 1 - y_true\n",
    "    union        = y_true + (not_true * y_pred)\n",
    "    iou          = (torch.sum(intersection * weight)) / (torch.sum(union * weight))\n",
    "\n",
    "    loss = 1-iou\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def border_loss(output,y,pool_size=(9,9), pad=(4,4)):\n",
    "    y      = y.type(torch.float32)\n",
    "    \n",
    "    output = output.type(torch.float32)\n",
    "    \n",
    "    averaged_mask = F.avg_pool2d(y,kernel_size=pool_size,stride=(1,1), padding=pad)\n",
    "    border = (averaged_mask>0.005).type(torch.float32) * (averaged_mask<0.995).type(torch.float32)\n",
    "    weight = torch.ones_like(averaged_mask)\n",
    "    w0     = torch.sum(weight)\n",
    "    weight+= border*2\n",
    "    w1     = torch.sum(weight)\n",
    "    weight*= (w0/w1)\n",
    "    loss   = weighted_bce_loss(output,y,weight) + weighted_dice_loss(output,y,weight) + iou_loss(output,y,weight)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "################ Metrics #######################\n",
    "def IoU_pr_rec_f1(y_true, y_pred):\n",
    "    \n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    y_pred = ((y_pred)*1.).type(torch.float32)\n",
    "    \n",
    "    tp = torch.sum(y_true*(y_pred))\n",
    "    tn = torch.sum((1-y_true)*((1-y_pred)))\n",
    "    fp = torch.sum((1-y_true)*(y_pred))\n",
    "    fn = torch.sum((y_true)*((1-y_pred)))\n",
    "    \n",
    "    pr  = (tp/(tp+fp))\n",
    "    rec = (tp/(tp+fn))\n",
    "    f1  = ((2*pr*rec)/(pr+rec))\n",
    "    tnr = (tn/(tn+fp))\n",
    "    fpr = (fp/(fp+tn))\n",
    "    \n",
    "    intersection = y_true*y_pred\n",
    "    not_true     = 1 - y_true\n",
    "    union        = y_true + (not_true * y_pred)\n",
    "    iou         = (torch.sum(intersection)) / (torch.sum(union))\n",
    "    \n",
    "    return iou, pr, rec, f1, tnr, fpr\n",
    "\n",
    "# Saving Metrics\n",
    "def metrics():\n",
    "    x = np.arange(0,1,0.05)\n",
    "    IoU_      = []\n",
    "    threshold = []\n",
    "    precision = []\n",
    "    recall    = []\n",
    "    F_score   = []\n",
    "    mF_score  = []\n",
    "    TNR       = []\n",
    "    FPR       = []\n",
    "    name_list = []\n",
    "\n",
    "    dict_1 = {'Name':name_list,\n",
    "              'Precision':precision,\n",
    "              'Recall':recall,\n",
    "              'IoU':IoU_,\n",
    "              'F-Score':F_score,\n",
    "              'mF-Score':mF_score,\n",
    "              'Threshold': threshold,\n",
    "              'True Negative Rate':TNR,\n",
    "              'False Positive Rate':FPR}\n",
    "    return dict_1\n",
    "\n",
    "def best_f_score(name, test_masks, predictions) :\n",
    "    dict_1 = metrics()\n",
    "    y = 0\n",
    "    outer = 0\n",
    "    check = 0\n",
    "    x = 0 \n",
    "    y = 1\n",
    "    while outer<3:    \n",
    "        if y>1:\n",
    "            m = y-1\n",
    "            y-= m\n",
    "        z = np.linspace(x, y, 21)\n",
    "        for i in z:\n",
    "#             print(i)\n",
    "            y_true = torch.from_numpy(test_masks)\n",
    "            y_pred = torch.from_numpy((predictions>i)*1)\n",
    "\n",
    "            tp = torch.sum(y_true*(y_pred),dim=[1,2,3])\n",
    "            tn = torch.sum((1-y_true)*((1-y_pred)),dim=[1,2,3])\n",
    "            fp = torch.sum((1-y_true)*(y_pred),dim=[1,2,3])\n",
    "            fn = torch.sum((y_true)*((1-y_pred)),dim=[1,2,3])\n",
    "\n",
    "            pr  = (tp/(tp+fp))\n",
    "            rec = (tp/(tp+fn))\n",
    "            score  = ((2*pr*rec)/(pr+rec))\n",
    "            idx    = torch.isnan(score)\n",
    "            score[idx] = 0\n",
    "            score  = torch.sum(score)/len(X_test)\n",
    "            \n",
    "            a,b,c,d,e,f = IoU_pr_rec_f1(torch.from_numpy(test_masks), torch.from_numpy(predictions>i))\n",
    "            dict_1['IoU'].append(a.numpy())\n",
    "            dict_1['Threshold'].append(i)\n",
    "            dict_1['Precision'].append(b.numpy())\n",
    "            dict_1['Recall'].append(c.numpy())\n",
    "            dict_1['F-Score'].append(d.numpy())\n",
    "            dict_1['mF-Score'].append(score.cpu().detach().numpy())\n",
    "            dict_1['True Negative Rate'].append(e.numpy())\n",
    "            dict_1['False Positive Rate'].append(f.numpy())\n",
    "            dict_1['Name'].append(name)\n",
    "            if d>check:\n",
    "                check = d\n",
    "                x = i\n",
    "            else:\n",
    "                pass\n",
    "        if outer == 0:\n",
    "            y = x+0.1\n",
    "        elif outer==1:\n",
    "            y = x+0.01\n",
    "        outer+=1\n",
    "    \n",
    "    df = pd.DataFrame(dict_1)\n",
    "    df = df.sort_values(by=['F-Score'], ascending=False)\n",
    "    df = df.iloc[0:1]\n",
    "    \n",
    "    AP = average_precision_score(test_masks.reshape(-1), predictions.reshape(-1))\n",
    "    df['AP'] = AP\n",
    "        \n",
    "    return df\n",
    "\n",
    "dict_1 = metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "################ Metadata ########################\n",
    "def metadata(Y):\n",
    "    list_ = defaultdict(list)\n",
    "    for i in range(len(Y)):\n",
    "        water = (Y[i].sum()/np.prod(Y[i].shape))*100\n",
    "        list_[f'Image_{i}'].append(water)\n",
    "        list_[f'Image_{i}'].append(100-water)\n",
    "    for i in range(len(Y)):\n",
    "        water = (Y[i].sum()/np.prod(Y[i].shape))*100\n",
    "        if water>90:\n",
    "            list_[f'Image_{i}'].append(1)\n",
    "        else:\n",
    "            list_[f'Image_{i}'].append(0)\n",
    "    for i in range(len(Y)):\n",
    "        water = (Y[i].sum()/np.prod(Y[i].shape))*100\n",
    "        if water<10:\n",
    "            list_[f'Image_{i}'].append(1)\n",
    "        else:\n",
    "            list_[f'Image_{i}'].append(0)\n",
    "    return list_\n",
    "\n",
    "def water_percentages(df_meta):\n",
    "    water_p = df_meta[0].values\n",
    "    indices = np.arange(len(water_p))\n",
    "    dict_idx = {}\n",
    "    limit = 10\n",
    "    for i in range(12):\n",
    "        if i==0:\n",
    "            idx = np.where(water_p==0)\n",
    "            dict_idx[f'Index=0'] = indices[idx[0]]\n",
    "            water_p = np.delete(water_p, idx)\n",
    "            indices = np.delete(indices, idx)\n",
    "        elif i==11:\n",
    "            idx = np.where(water_p==100)\n",
    "            dict_idx[f'Index=100'] = indices[idx[0]]\n",
    "            water_p = np.delete(water_p, idx)\n",
    "            indices = np.delete(indices, idx)\n",
    "        else:\n",
    "            idx = np.where(water_p<limit)\n",
    "            dict_idx[f'Index_{limit}'] = indices[idx[0]]\n",
    "            water_p = np.delete(water_p, idx)\n",
    "            indices = np.delete(indices, idx)\n",
    "            limit+=10\n",
    "            \n",
    "    return dict_idx\n",
    "\n",
    "def list_test(dict_idx):\n",
    "    counter = 0\n",
    "    list_ = []\n",
    "    dict_ ={}\n",
    "    lower = 0\n",
    "    upper = 10\n",
    "    for key in dict_idx.keys():\n",
    "\n",
    "        print(f'{key}:',len(dict_idx[key]))\n",
    "        counter+=len(dict_idx[key])\n",
    "        dict_['Water'+key.split('Index')[-1]] = [len(dict_idx[key]), len(dict_idx[key])/2053*100]\n",
    "        list_.append(list(dict_idx[key]))\n",
    "        lower+=10\n",
    "        upper+=10\n",
    "    print(f'Total Images: {counter}')\n",
    "    print('-'*10)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "############## F1 for Train Time Display 0.5 Threshold ##################\n",
    "def f1_score(y_pred, y_true, threshold=0.5):\n",
    "    \n",
    "    y_true = y_true.view(-1)\n",
    "    y_pred = y_pred.view(-1)\n",
    "    y_pred = ((y_pred>threshold)*1.).type(torch.float32)\n",
    "    \n",
    "    tp = torch.sum(y_true*(y_pred))\n",
    "    tn = torch.sum((1-y_true)*((1-y_pred)))\n",
    "    fp = torch.sum((1-y_true)*(y_pred))\n",
    "    fn = torch.sum((y_true)*((1-y_pred)))\n",
    "    \n",
    "    pr  = ((tp+1.)/(tp+fp+1.))\n",
    "    rec = ((tp+1.)/(tp+fn+1.))\n",
    "    f1  = ((2*pr*rec)/(pr+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HPCL\\AppData\\Local\\Temp/ipykernel_11692/789549544.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_train         = (X_train[...,1]-X_train[...,3])/(X_train[...,1]+X_train[...,3])\n",
      "C:\\Users\\HPCL\\AppData\\Local\\Temp/ipykernel_11692/789549544.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_test          = (X_test[...,1]-X_test[...,3])/(X_test[...,1]+X_test[...,3])\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_train_4500_30m_res.npy\")\n",
    "X_val   = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_val_500_30m_res.npy\")\n",
    "X_test  = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_test_2000_30m_res.npy\")\n",
    "\n",
    "Y_train         = (X_train[...,1]-X_train[...,3])/(X_train[...,1]+X_train[...,3])\n",
    "Y_val           = (X_val[...,1]-X_val[...,3])/(X_val[...,1]+X_val[...,3])\n",
    "Y_test          = (X_test[...,1]-X_test[...,3])/(X_test[...,1]+X_test[...,3])\n",
    "\n",
    "Y_train         = ((Y_train<1.)*1).astype('float32')\n",
    "Y_val           = ((Y_val<1.)*1).astype('float32')\n",
    "Y_test          = ((Y_test<1.)*1).astype('float32')\n",
    "\n",
    "X_train         = X_train[...,2::-1].copy()\n",
    "X_val           = X_val[...,2::-1].copy()\n",
    "X_test          = X_test[...,2::-1].copy()\n",
    "\n",
    "X_train         = X_train - X_train.min(axis=(1,2), keepdims=True) \n",
    "X_val           = X_val  - X_val.min(axis=(1,2), keepdims=True)\n",
    "X_test          = X_test - X_test.min(axis=(1,2), keepdims=True) \n",
    "\n",
    "X_train         = X_train / X_train.max(axis=(1,2), keepdims=True) \n",
    "X_val           = X_val  / X_val.max(axis=(1,2), keepdims=True)\n",
    "X_test          = X_test / X_test.max(axis=(1,2), keepdims=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images: 4500\n",
      "Test Images: 2000\n"
     ]
    }
   ],
   "source": [
    "#Get Metadata Sentinel\n",
    "df = metadata(Y_train)\n",
    "df_meta_train = pd.DataFrame.from_dict(df,orient='index')\n",
    "print('Test Images:',len(df_meta_train))\n",
    "\n",
    "#Get Metadata Landsat\n",
    "df = metadata(Y_test)\n",
    "df_meta_test = pd.DataFrame.from_dict(df,orient='index')\n",
    "print('Test Images:',len(df_meta_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index=0: 0\n",
      "Index_10: 138\n",
      "Index_20: 509\n",
      "Index_30: 450\n",
      "Index_40: 414\n",
      "Index_50: 304\n",
      "Index_60: 381\n",
      "Index_70: 365\n",
      "Index_80: 379\n",
      "Index_90: 483\n",
      "Index_100: 1077\n",
      "Index=100: 0\n",
      "Total Images: 4500\n",
      "----------\n",
      "\n",
      "Index=0: 0\n",
      "Index_10: 59\n",
      "Index_20: 215\n",
      "Index_30: 204\n",
      "Index_40: 185\n",
      "Index_50: 149\n",
      "Index_60: 173\n",
      "Index_70: 181\n",
      "Index_80: 155\n",
      "Index_90: 199\n",
      "Index_100: 480\n",
      "Index=100: 0\n",
      "Total Images: 2000\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "water_p_train = water_percentages(df_meta_train)\n",
    "water_p_test = water_percentages(df_meta_test)\n",
    "\n",
    "list_test_train = list_test(water_p_train)\n",
    "list_test_test = list_test(water_p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "################ Get Contours ##########################\n",
    "Y_train = np.array([binary_dilation(mask)-mask for mask in Y_train ], dtype='float64')\n",
    "Y_val   = np.array([binary_dilation(mask)-mask for mask in Y_val], dtype='float64')\n",
    "Y_test  = np.array([binary_dilation(mask)-mask for mask in Y_test], dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class NDWIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, images, masks, transform=None, test_transform=None):\n",
    "        self.images     = images\n",
    "        self.masks      = masks\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            augmentations = self.transforms(image=image, mask=mask)\n",
    "        \n",
    "        image = augmentations['image']\n",
    "        mask  = augmentations['mask']\n",
    "        mask  = mask[np.newaxis,:,:]\n",
    "        \n",
    "        return [image.type(torch.float32), \n",
    "                mask.type(torch.float32)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def data(trans, trans_test, X_train, Y_train, X_val, Y_val, X_test, Y_test, split=0.9, val=True, batch_size=16):\n",
    "    torch.manual_seed(49)\n",
    "    random.seed(49)\n",
    "    trainset= NDWIDataset(X_train, Y_train, transform=trans)\n",
    "\n",
    "    if val:\n",
    "        print(f'Training:{len(X_train)}, Validation:{len(X_val)}')\n",
    "        print(f'Testing: {len(X_test)}')\n",
    "        \n",
    "        valset  = NDWIDataset(X_val, Y_val, transform=trans_test)\n",
    "        testset = NDWIDataset(X_test, Y_test, transform=trans_test)\n",
    "        image_datasets = {'train': trainset, 'val': valset, 'test': testset}\n",
    "        batch_size = batch_size\n",
    "\n",
    "        dataloaders = {\n",
    "          'train': DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory = True, drop_last=True),#, num_workers=8),\n",
    "          'val': DataLoader(valset, batch_size=batch_size, shuffle=True, pin_memory = True, drop_last=True),#, num_workers=8),\n",
    "          'test': DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory = True, drop_last=True)#, num_workers=8)\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        print(f'Training:{len(X_train)}')\n",
    "        print(f'Testing: {len(X_test)}')\n",
    "        testset = NDWIDataset(X_test, Y_test, transform=trans_test)\n",
    "        image_datasets = {'train': trainset, 'test': testset}\n",
    "        batch_size = batch_size\n",
    "\n",
    "        dataloaders = {\n",
    "          'train': DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory = True),#, num_workers=8),\n",
    "          'test': DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory = True)#, num_workers=8)\n",
    "        }\n",
    "        \n",
    "    \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = A.Compose([\n",
    "    ToTensorV2()])\n",
    "trans_test = A.Compose([\n",
    "             ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_rand(dataloader, set_='train'):\n",
    "    if set_==None:\n",
    "        for x,y in dataloader:\n",
    "            x,y = x.numpy().transpose([0,2,3,1]), y.numpy().squeeze()\n",
    "            break\n",
    "    else:\n",
    "        for x,y in dataloader[set_]:\n",
    "            x,y = x.numpy().transpose([0,2,3,1]), y.numpy().squeeze()\n",
    "            break\n",
    "    rand = np.random.randint(0,x.shape[0])\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(x[rand])\n",
    "    plt.title('Image')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(y[rand])\n",
    "    plt.title('Contour')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:4500, Validation:500\n",
      "Testing: 2000\n"
     ]
    }
   ],
   "source": [
    "dataloaders = data(trans, trans_test, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_rand(dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def train(model, dataloaders, loss_fn, optimizer, acc_fn, random_state=49, epochs=1):\n",
    "    torch.manual_seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "    start = time.time()                                        #Initialize time to calculate time it takes to train model\n",
    "    model.to(device)                                               #Move model to GPU     \n",
    "\n",
    "    counter=0\n",
    "    train_loss, valid_loss = [], []                            #Running training and validation loss\n",
    "    val_epoch, f1_epoch = [0],[0]\n",
    "    loss_list = []\n",
    "    times     = []\n",
    "#     epoch = 1\n",
    "    for epoch in range(epochs):\n",
    "        start_epoch = time.time()\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        print(scheduler.get_last_lr())\n",
    "    \n",
    "\n",
    "    #########################################Begin Model Training######################################################\n",
    "    ###################################################################################################################\n",
    "        \n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()                             # Set training mode all the layers including batchnorm and dropout work in this\n",
    "                dataloader = dataloaders['train']         #get the training data\n",
    "            else:\n",
    "                model.eval()                              # Set model to evaluate mode deactivates the batchnorm and dropout layers\n",
    "                dataloader = dataloaders['val']           #get the validation data\n",
    "\n",
    "            running_loss = 0.0                            #running loss to be used for visualization later\n",
    "            step = 0                                      #Batch number\n",
    "            \n",
    "            if phase == 'train':  \n",
    "                f1 = []\n",
    "                for inputs, labels in dataloader:\n",
    "                    x, y = inputs.to(device), labels.to(device)\n",
    "                    step += 1\n",
    "\n",
    "                    optimizer.zero_grad()                                   # zero the gradients\n",
    "                    outputs = model(x)                                      #get model output for a given input\n",
    "\n",
    "                    #################Metrics###################\n",
    "                    f1.append(acc_fn(outputs, y).cpu().detach().numpy())\n",
    "                    ############################################\n",
    "\n",
    "                    ##################Calculate Loss, backprop, and update###############\n",
    "                    loss           = loss_fn(outputs, y)\n",
    "                    train_loss.append(loss.cpu().detach().numpy())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    print(f'Current step: {step}, AllocMem (Mb): {torch.cuda.memory_allocated()/1024/1024:.3f}, Loss: {loss:.3f},  F1: {np.mean(f1):.3f}', end='\\r') \n",
    "                    ######################################################################\n",
    "        \n",
    "            else:  \n",
    "                loss_val = []\n",
    "                f1=[]\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in dataloader:\n",
    "                        x, y = inputs.to(device), labels.to(device)\n",
    "                        optimizer.zero_grad()                                   # zero the gradients\n",
    "                        outputs = model(x)                                      #get model output for a given input\n",
    "\n",
    "                        #################Metrics###################\n",
    "                        f1.append(acc_fn(outputs, y).cpu().detach().numpy())\n",
    "                        ############################################\n",
    "\n",
    "                        ##################Calculate Loss, backprop, and update###############\n",
    "                        valid_loss.append(loss_fn(outputs, y).cpu().detach().numpy())\n",
    "                        loss_val.append(valid_loss[-1])\n",
    "                val_epoch.append(np.mean(loss_val))\n",
    "                f1_epoch.append(np.mean(f1))\n",
    "                print()\n",
    "                print()\n",
    "                print(f' Loss val: {val_epoch[-1]:.3f}, F-Score val:{f1_epoch[-1]:.3f} \\n') \n",
    "                ######################################################################\n",
    "                \n",
    "                ##### Check validation #####\n",
    "#                 if f1_epoch[-1] > f1_epoch[-2]:\n",
    "#                     counter = 0\n",
    "#                     print('Counter Reset')\n",
    "#                 else:\n",
    "#                     counter+=1\n",
    "#                     print(f'Counter is {counter}')\n",
    "\n",
    "            print()\n",
    "            time_elapsed = time.time() - start_epoch\n",
    "            times.append(time_elapsed)\n",
    "            print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "            print('-' * 10)      \n",
    "\n",
    "        scheduler.step()\n",
    "#         torch.save(model, path+ '\\\\' + f'Epcoh_{str(epoch).zfill(3)}'+ '.pth')\n",
    "        epoch+=1\n",
    "    #########################################End Model Training######################################################\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    #Total training time including time to test\n",
    "    time_elapsed = time.time() - start\n",
    "    print('\\n Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "    \n",
    "    return {'Train Loss':train_loss,\n",
    "            'Valid Loss':valid_loss,\n",
    "            'Times'     :times,\n",
    "            'Epochs'    : epoch+1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def test_pred(model,X_test,batch_size=32):\n",
    "    model.eval()\n",
    "    if model.training==True:\n",
    "        raise ValueError('Model is in training mode')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    predictions = np.zeros([len(X_test),1,X_test.shape[1],X_test.shape[2]])\n",
    "    i = 0\n",
    "    for x, y in tqdm(dataloaders['test']):\n",
    "        predictions[i:i+batch_size] = model(x.cuda()).cpu().detach().numpy()\n",
    "        i+=batch_size\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Results\\Landsat\\Final Models\\2dil-ndwi\"\n",
    "csv_dir   = r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Results\\Landsat\\Final Models\\2dil-ndwi\\F-scores.csv\"\n",
    "dataset = 'Landsat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:4500, Validation:500\n",
      "Testing: 2000\n"
     ]
    }
   ],
   "source": [
    "trans = A.Compose([\n",
    "    ToTensorV2()])\n",
    "trans_test = A.Compose([\n",
    "                ToTensorV2()])\n",
    "\n",
    "batch_size = 32\n",
    "dataloaders = data(trans, trans_test, X_train, Y_train, X_val, Y_val, X_test, Y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.787,  F1: 0.182\n",
      "Training complete in 0m 14s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.899, F-Score val:0.103 \n",
      "\n",
      "\n",
      "Training complete in 0m 15s\n",
      "----------\n",
      "Epoch 2\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.633,  F1: 0.250\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.722, F-Score val:0.244 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 3\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.624,  F1: 0.288\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.728, F-Score val:0.261 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 4\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.615,  F1: 0.311\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.710, F-Score val:0.274 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 5\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.562,  F1: 0.318\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.591, F-Score val:0.316 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 6\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.574,  F1: 0.330\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.562, F-Score val:0.334 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 7\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.575,  F1: 0.343\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 2.192, F-Score val:0.196 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 8\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.587,  F1: 0.341\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.585, F-Score val:0.314 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 9\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.510,  F1: 0.344\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.538, F-Score val:0.351 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 10\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.556,  F1: 0.342\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.569, F-Score val:0.334 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 11\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.524,  F1: 0.345\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.519, F-Score val:0.355 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 12\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.483,  F1: 0.367\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.509, F-Score val:0.352 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 13\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.489,  F1: 0.366\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.515, F-Score val:0.354 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 14\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.520,  F1: 0.375\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.493, F-Score val:0.375 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 15\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.492,  F1: 0.383\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.477, F-Score val:0.379 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 16\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.513,  F1: 0.390\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.472, F-Score val:0.382 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 17\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.437,  F1: 0.394\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.469, F-Score val:0.381 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 18\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.558,  F1: 0.394\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.480, F-Score val:0.381 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 19\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.431,  F1: 0.397\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.470, F-Score val:0.377 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 20\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.420,  F1: 0.401\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.563, F-Score val:0.335 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 21\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.407,  F1: 0.407\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.447, F-Score val:0.394 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 22\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.493,  F1: 0.401\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.926, F-Score val:0.241 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 23\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.393,  F1: 0.412\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.436, F-Score val:0.406 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 24\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.437,  F1: 0.401\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.478, F-Score val:0.371 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 25\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.438,  F1: 0.411\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.449, F-Score val:0.394 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 26\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.498,  F1: 0.410\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.453, F-Score val:0.388 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 27\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.383,  F1: 0.421\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.450, F-Score val:0.394 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 28\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.445,  F1: 0.424\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.441, F-Score val:0.404 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 29\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.362,  F1: 0.416\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.453, F-Score val:0.400 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 30\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.432,  F1: 0.424\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.440, F-Score val:0.405 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 31\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.402,  F1: 0.423\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.439, F-Score val:0.397 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 32\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.413,  F1: 0.423\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.426, F-Score val:0.409 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 33\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.445,  F1: 0.425\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.433, F-Score val:0.412 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 34\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.387,  F1: 0.437\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.425, F-Score val:0.411 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 35\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.373,  F1: 0.443\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.410, F-Score val:0.420 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 36\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.387,  F1: 0.448\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.416, F-Score val:0.415 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 37\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.370,  F1: 0.448\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.418, F-Score val:0.413 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 38\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.431,  F1: 0.453\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.412, F-Score val:0.415 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 39\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.365,  F1: 0.452\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.411, F-Score val:0.422 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 40\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.350,  F1: 0.454\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.406, F-Score val:0.424 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 41\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.318,  F1: 0.458\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.403, F-Score val:0.428 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 42\n",
      "[0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.301,  F1: 0.464\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.399, F-Score val:0.429 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 43\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.355,  F1: 0.461\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.435, F-Score val:0.415 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 44\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.417,  F1: 0.460\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.408, F-Score val:0.422 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 45\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.370,  F1: 0.467\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.398, F-Score val:0.431 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 46\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.352,  F1: 0.470\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.403, F-Score val:0.430 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 47\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.361,  F1: 0.465\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.402, F-Score val:0.429 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 48\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.341,  F1: 0.467\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.425, F-Score val:0.415 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 49\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 343.148, Loss: 1.272,  F1: 0.472\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.398, F-Score val:0.430 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "Epoch 50\n",
      "[0.003]\n",
      "Current step: 140, AllocMem (Mb): 342.648, Loss: 1.354,  F1: 0.480\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      "\n",
      " Loss val: 1.400, F-Score val:0.432 \n",
      "\n",
      "\n",
      "Training complete in 0m 7s\n",
      "----------\n",
      "\n",
      " Training complete in 5m 55s\n"
     ]
    }
   ],
   "source": [
    "name = 'PAN'\n",
    "loss_name = 'BCE+IoU+Dice, 9x9 Border'\n",
    "\n",
    "\n",
    "model = smp.PAN(encoder_name='resnet34', encoder_weights=None, activation='sigmoid').to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=0.003)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(opt, milestones=[100,180], gamma=0.1)\n",
    "history = train(model, dataloaders, loss_fn = border_loss, optimizer = opt, acc_fn = f1_score, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 62/62 [00:01<00:00, 48.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>IoU</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>mF-Score</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>AP</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PAN</td>\n",
       "      <td>0.32975633523999587</td>\n",
       "      <td>0.6434712061259927</td>\n",
       "      <td>0.27881455862327564</td>\n",
       "      <td>0.4360515865935043</td>\n",
       "      <td>0.4275104147461696</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.9858268775579014</td>\n",
       "      <td>0.014173122442098535</td>\n",
       "      <td>0.326094</td>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name            Precision              Recall                  IoU  \\\n",
       "49  PAN  0.32975633523999587  0.6434712061259927  0.27881455862327564   \n",
       "\n",
       "               F-Score            mF-Score  Threshold  True Negative Rate  \\\n",
       "49  0.4360515865935043  0.4275104147461696     0.5035  0.9858268775579014   \n",
       "\n",
       "     False Positive Rate        AP  Time  \n",
       "49  0.014173122442098535  0.326094  6.96  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### F-score and Save Model #################\n",
    "predictions = test_pred(model, X_test, batch_size=32)\n",
    "df = best_f_score(name, Y_test[:,np.newaxis,:,:], predictions)\n",
    "df['Time'] = round(np.mean(history['Times']),2)\n",
    "df.to_csv(csv_dir, mode='a')\n",
    "torch.save({'Dataset'   : f'{dataset}_5K_2K_30m {name}',\n",
    "            'Batch Size': batch_size,\n",
    "            'Loss'      : loss_name,\n",
    "            'Model'     : model,\n",
    "            'F-score'   : df['F-Score'].values[0],\n",
    "            'Time'      : round(np.mean(history['Times']),2),\n",
    "            'Train Loss': history['Train Loss'],\n",
    "            'Validation Loss': history['Valid Loss'],\n",
    "            'Epochs'    : history['Epochs']},\n",
    "          model_dir + '\\\\' + name +'.pth')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HPCL\\AppData\\Local\\Temp/ipykernel_11692/2657704787.py:12: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df_f1 = df_f1.append(pd.Series(), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "################### F-score By Group ################\n",
    "path = csv_dir.replace('F-scores.csv', 'F-scores_group.csv')\n",
    "dict_f1 = {}\n",
    "for key, list_ in zip(water_p_test.keys(),list_test_test):\n",
    "    y_true= torch.from_numpy(Y_test[:,np.newaxis,:,:][list_])\n",
    "    y_pred= torch.from_numpy(predictions[list_])\n",
    "    dict_f1['Water'+key.split('Index')[-1]] = f1_score(y_pred.reshape(-1), y_true.reshape(-1), threshold=df['Threshold'].values[0])\n",
    "\n",
    "\n",
    "df_f1 = pd.DataFrame.from_dict(dict_f1, orient='index')\n",
    "df_f1 = pd.DataFrame(df_f1[0].rename('F1_score'))\n",
    "df_f1 = df_f1.append(pd.Series(), ignore_index=True)\n",
    "df_f1.index.names = [name]\n",
    "df_f1.to_csv(path, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "793px",
    "left": "40px",
    "top": "110px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 496,
   "position": {
    "height": "518px",
    "left": "1676px",
    "right": "20px",
    "top": "120px",
    "width": "224px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
