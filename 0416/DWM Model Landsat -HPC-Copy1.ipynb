{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.color import *\n",
    "from skimage.morphology import *\n",
    "from skimage.feature import *\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop \n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import *\n",
    "from tqdm.notebook import tqdm\n",
    "import imageio as io\n",
    "import deepwatermap\n",
    "import tifffile as tiff\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Always run this otherwise TF crashes\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print('so')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(y_true,y_pred):\n",
    "    threshold = 0.5\n",
    "\n",
    "    y_true = tf.reshape(y_true,[-1])\n",
    "    y_pred = tf.reshape(y_pred,[-1])\n",
    "    y_pred = (y_pred>threshold)\n",
    "    y_pred = tf.cast(y_pred,dtype=tf.float32)\n",
    "\n",
    "    tp = K.sum(y_true*(y_pred))\n",
    "    tn = K.sum((1-y_true)*((1-y_pred)))\n",
    "    fp = K.sum((1-y_true)*(y_pred))\n",
    "    fn = K.sum((y_true)*((1-y_pred)))\n",
    "\n",
    "    pr  = ((tp+1.)/(tp+fp+1.))\n",
    "    rec = ((tp+1.)/(tp+fn+1.))\n",
    "    f1  = ((2*pr*rec)/(pr+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) *     (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def loss_kaggle(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(11, 11), strides=(1, 1), padding='same', pool_mode='avg', data_format=\"channels_last\")\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    \n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) +\\\n",
    "    weighted_dice_loss(y_true, y_pred, weight) +\\\n",
    "    IoU_loss(y_true, y_pred, weight)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def IoU(y_true, y_pred, weight):\n",
    "    weight = weight*weight\n",
    "    intersection = y_true*y_pred\n",
    "    not_true     = 1 - y_true\n",
    "    union        = y_true + (not_true * y_pred)\n",
    "    score        = (K.sum(weight * intersection)) / (K.sum(weight * union))\n",
    "    return score\n",
    "\n",
    "\n",
    "# IoU as a loss function\n",
    "def IoU_loss(y_true, y_pred, weight):\n",
    "    return 1 - IoU(y_true, y_pred, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Metrics #######################\n",
    "def IoU_pr_rec_f1(y_true, y_pred):\n",
    "    \n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    y_pred = ((y_pred)*1.).astype('float32')\n",
    "    \n",
    "    tp = np.sum(y_true*(y_pred))\n",
    "    tn = np.sum((1-y_true)*((1-y_pred)))\n",
    "    fp = np.sum((1-y_true)*(y_pred))\n",
    "    fn = np.sum((y_true)*((1-y_pred)))\n",
    "    \n",
    "    pr  = (tp/(tp+fp))\n",
    "    rec = (tp/(tp+fn))\n",
    "    f1  = ((2*pr*rec)/(pr+rec))\n",
    "    tnr = (tn/(tn+fp))\n",
    "    fpr = (fp/(fp+tn))\n",
    "    \n",
    "    intersection = y_true*y_pred\n",
    "    not_true     = 1 - y_true\n",
    "    union        = y_true + (not_true * y_pred)\n",
    "    iou         = (np.sum(intersection)) / (np.sum(union))\n",
    "    \n",
    "    return iou, pr, rec, f1, tnr, fpr\n",
    "\n",
    "# Saving Metrics\n",
    "def metrics():\n",
    "    x = np.arange(0,1,0.05)\n",
    "    IoU_      = []\n",
    "    threshold = []\n",
    "    precision = []\n",
    "    recall    = []\n",
    "    F_score   = []\n",
    "    TNR       = []\n",
    "    FPR       = []\n",
    "    name_list = []\n",
    "\n",
    "    dict_1 = {'Threshold': threshold,\n",
    "              'Name':name_list,\n",
    "              'IoU':IoU_,\n",
    "              'Precision':precision,\n",
    "              'Recall':recall,\n",
    "              'F-Score':F_score,\n",
    "              'True Negative Rate':TNR,\n",
    "              'False Positive Rate':FPR}\n",
    "    return dict_1\n",
    "\n",
    "#calculate F-scores only\n",
    "#update other parameters after best f-socore is found\n",
    "#\n",
    "def best_f_score(name, test_masks, predictions) :\n",
    "    dict_1 = metrics()\n",
    "    outer = 0\n",
    "    best_f_score = 0\n",
    "    x = 0       \n",
    "    y = 1\n",
    "    delta = 0.05\n",
    "    while outer<3:\n",
    "        z = np.arange(x, y, delta)         #\n",
    "        for threshold in z:\n",
    "            iou,precision,recall,f_score,tnr,fpr = IoU_pr_rec_f1((test_masks), (predictions>threshold))\n",
    "            dict_1['IoU'].append(iou)\n",
    "            dict_1['Threshold'].append(threshold)\n",
    "            dict_1['Precision'].append(precision)\n",
    "            dict_1['Recall'].append(recall)\n",
    "            dict_1['F-Score'].append(f_score)\n",
    "            dict_1['True Negative Rate'].append(tnr)\n",
    "            dict_1['False Positive Rate'].append(fpr)\n",
    "            dict_1['Name'].append(name)\n",
    "            if f_score>best_f_score:\n",
    "                best_f_score = f_score\n",
    "                x = threshold\n",
    "            else:\n",
    "                pass\n",
    "        x-=     delta\n",
    "        y = x + delta\n",
    "        delta*= 0.1\n",
    "        outer+= 1\n",
    "        \n",
    "    return dict_1\n",
    "\n",
    "dict_1 = metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4608, 513)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(49)\n",
    "pop = np.arange(5121)\n",
    "sample_train = np.random.choice(pop, 4608, replace=False)\n",
    "sample_test  = np.delete(pop, sample_train)\n",
    "len(sample_train), len(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X      = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Sentinel uint16 Data 0%water and 0%land exclude\\X_train_sentinel_6_channles_5121.npy\")\n",
    "X_test = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Sentinel uint16 Data 0%water and 0%land exclude\\X_test_sentinel_6_channles_2053.npy\")\n",
    "X_train= X[sample_train]\n",
    "X_val  = X[sample_test]\n",
    "\n",
    "Y_train         = (X_train[...,1]-X_train[...,3])/(X_train[...,1]+X_train[...,3])\n",
    "Y_val           = (X_val[...,1]-X_val[...,3])/(X_val[...,1]+X_val[...,3])\n",
    "Y_test          = (X_test[...,1]-X_test[...,3])/(X_test[...,1]+X_test[...,3])\n",
    "\n",
    "Y_train         = ((Y_train<1.)*1).astype('float32')\n",
    "Y_val           = ((Y_val<1.)*1).astype('float32')\n",
    "Y_test          = ((Y_test<1.)*1).astype('float32')\n",
    "\n",
    "X_train         = X_train[...,2::-1].copy()\n",
    "X_val           = X_val[...,2::-1].copy()\n",
    "X_test          = X_test[...,2::-1].copy()\n",
    "\n",
    "X_train         = np.clip(X_train, 0, 3558) \n",
    "X_val           = np.clip(X_val, 0, 3558)\n",
    "X_test          = np.clip(X_test, 0, 3558) \n",
    "\n",
    "X_train         = X_train - X_train.min(axis=(1,2), keepdims=True) \n",
    "X_val           = X_val  - X_val.min(axis=(1,2), keepdims=True)\n",
    "X_test          = X_test - X_test.min(axis=(1,2), keepdims=True) \n",
    "\n",
    "X_train         = X_train / X_train.max(axis=(1,2), keepdims=True) \n",
    "X_val           = X_val  / X_val.max(axis=(1,2), keepdims=True)\n",
    "X_test          = X_test / X_test.max(axis=(1,2), keepdims=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Get Contours ##########################\n",
    "Y_train = np.array([binary_dilation(binary_dilation(mask))-mask for mask in Y_train ], dtype='float64')[...,np.newaxis]\n",
    "Y_val   = np.array([binary_dilation(binary_dilation(mask))-mask for mask in Y_val], dtype='float64')[...,np.newaxis]\n",
    "Y_test  = np.array([binary_dilation(binary_dilation(mask))-mask for mask in Y_test], dtype='float64')[...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, None, None,   12          ['input_1[0][0]']                \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, None, None,   16         ['conv2d[0][0]']                 \n",
      " alization)                     4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, None, None,   1600        ['batch_normalization[0][0]']    \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, None, None,   64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   16)                                                               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, None,   0           ['batch_normalization_1[0][0]']  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, None, None,   2304        ['activation[0][0]']             \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, None, None,   64         ['conv2d_2[0][0]']               \n",
      " rmalization)                   16)                                                               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, None,   0           ['batch_normalization_2[0][0]']  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, None, None,   0           ['activation[0][0]',             \n",
      "                                16)                               'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, None, None,   25600       ['add[0][0]']                    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, None, None,   256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, None,   0           ['batch_normalization_3[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, None, None,   36864       ['activation_2[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, None, None,   256        ['conv2d_4[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, None, None,   0           ['batch_normalization_4[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, None, None,   0           ['activation_2[0][0]',           \n",
      "                                64)                               'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, None, None,   409600      ['add_1[0][0]']                  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, None, None,   1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                   256)                                                              \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, None, None,   0           ['batch_normalization_5[0][0]']  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, None, None,   589824      ['activation_4[0][0]']           \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, None, None,   1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                   256)                                                              \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, None, None,   0           ['batch_normalization_6[0][0]']  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, None, None,   0           ['activation_4[0][0]',           \n",
      "                                256)                              'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, None, None,   6553600     ['add_2[0][0]']                  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, None, None,   4096       ['conv2d_7[0][0]']               \n",
      " rmalization)                   1024)                                                             \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, None, None,   0           ['batch_normalization_7[0][0]']  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, None, None,   9437184     ['activation_6[0][0]']           \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, None, None,   4096       ['conv2d_8[0][0]']               \n",
      " rmalization)                   1024)                                                             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, None, None,   0           ['batch_normalization_8[0][0]']  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, None, None,   0           ['activation_6[0][0]',           \n",
      "                                1024)                             'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, None, None,   9437184     ['add_3[0][0]']                  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, None, None,   4096       ['conv2d_9[0][0]']               \n",
      " rmalization)                   1024)                                                             \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, None, None,   0           ['batch_normalization_9[0][0]']  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, None, None,   9437184     ['activation_8[0][0]']           \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, None, None,   4096       ['conv2d_10[0][0]']              \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, None, None,   0           ['batch_normalization_10[0][0]'] \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, None, None,   0           ['activation_8[0][0]',           \n",
      "                                1024)                             'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, None, None,   0           ['add_4[0][0]',                  \n",
      "                                1024)                             'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, None, None,   0           ['add_5[0][0]']                  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, None, None,   589824      ['lambda[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, None, None,   1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, None, None,   0           ['batch_normalization_11[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, None, None,   589824      ['activation_10[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, None, None,   1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, None, None,   0           ['batch_normalization_12[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, None, None,   0           ['activation_10[0][0]',          \n",
      "                                256)                              'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, None, None,   0           ['add_6[0][0]',                  \n",
      "                                256)                              'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, None, None,   0           ['add_7[0][0]']                  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, None, None,   36864       ['lambda_1[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, None, None,   256        ['conv2d_13[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, None, None,   0           ['batch_normalization_13[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, None, None,   36864       ['activation_12[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, None, None,   256        ['conv2d_14[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, None, None,   0           ['batch_normalization_14[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, None, None,   0           ['activation_12[0][0]',          \n",
      "                                64)                               'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, None, None,   0           ['add_8[0][0]',                  \n",
      "                                64)                               'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, None, None,   0           ['add_9[0][0]']                  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, None, None,   2304        ['lambda_2[0][0]']               \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, None, None,   64         ['conv2d_15[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, None, None,   0           ['batch_normalization_15[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, None, None,   2304        ['activation_14[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, None, None,   64         ['conv2d_16[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, None, None,   0           ['batch_normalization_16[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, None, None,   0           ['activation_14[0][0]',          \n",
      "                                16)                               'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, None, None,   0           ['add_10[0][0]',                 \n",
      "                                16)                               'add[0][0]']                    \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, None, None,   0           ['add_11[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, None, None,   144         ['lambda_3[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, None, None,   16         ['conv2d_17[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, None, None,   0           ['batch_normalization_17[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, None, None,   144         ['activation_16[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, None, None,   16         ['conv2d_18[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, None, None,   0           ['batch_normalization_18[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, None, None,   0           ['activation_16[0][0]',          \n",
      "                                4)                                'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, None, None,   0           ['add_12[0][0]',                 \n",
      "                                4)                                'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, None, None,   4           ['add_13[0][0]']                 \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, None, None,   4          ['conv2d_19[0][0]']              \n",
      " ormalization)                  1)                                                                \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, None, None,   0           ['batch_normalization_19[0][0]'] \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 37,211,044\n",
      "Trainable params: 37,200,138\n",
      "Non-trainable params: 10,906\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = deepwatermap.model()\n",
    "opt   = Adam(learning_rate=0.003)\n",
    "model.compile(optimizer=opt, loss= loss_kaggle, metrics=[F1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "144/144 [==============================] - 22s 57ms/step - loss: 2.1962 - F1: 0.2354 - val_loss: 2.0154 - val_F1: 0.4024\n",
      "Epoch 2/50\n",
      "144/144 [==============================] - 7s 52ms/step - loss: 1.9119 - F1: 0.4153 - val_loss: 1.8212 - val_F1: 0.4669\n",
      "Epoch 3/50\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 1.7108 - F1: 0.5001 - val_loss: 1.6327 - val_F1: 0.4753\n",
      "Epoch 4/50\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 1.5617 - F1: 0.5393 - val_loss: 1.4986 - val_F1: 0.5463\n",
      "Epoch 5/50\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 1.4348 - F1: 0.5710 - val_loss: 1.3720 - val_F1: 0.5865\n",
      "Epoch 6/50\n",
      "144/144 [==============================] - 8s 52ms/step - loss: 1.3314 - F1: 0.5975 - val_loss: 1.2941 - val_F1: 0.5895\n",
      "Epoch 7/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 1.2527 - F1: 0.6138 - val_loss: 1.2688 - val_F1: 0.5739\n",
      "Epoch 8/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 1.1804 - F1: 0.6312 - val_loss: 1.2056 - val_F1: 0.6184\n",
      "Epoch 9/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 1.1262 - F1: 0.6432 - val_loss: 1.1964 - val_F1: 0.5881\n",
      "Epoch 10/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 1.0734 - F1: 0.6582 - val_loss: 1.1367 - val_F1: 0.6269\n",
      "Epoch 11/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 1.0196 - F1: 0.6755 - val_loss: 1.1330 - val_F1: 0.6043\n",
      "Epoch 12/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.9711 - F1: 0.6912 - val_loss: 1.1127 - val_F1: 0.6216\n",
      "Epoch 13/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.9251 - F1: 0.7077 - val_loss: 1.0974 - val_F1: 0.6284\n",
      "Epoch 14/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.8806 - F1: 0.7226 - val_loss: 1.0945 - val_F1: 0.6189\n",
      "Epoch 15/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.8411 - F1: 0.7359 - val_loss: 1.0934 - val_F1: 0.6131\n",
      "Epoch 16/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.7966 - F1: 0.7526 - val_loss: 1.0835 - val_F1: 0.6206\n",
      "Epoch 17/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.7600 - F1: 0.7649 - val_loss: 1.0812 - val_F1: 0.6155\n",
      "Epoch 18/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.7209 - F1: 0.7791 - val_loss: 1.1010 - val_F1: 0.5923\n",
      "Epoch 19/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.6877 - F1: 0.7900 - val_loss: 1.0940 - val_F1: 0.6035\n",
      "Epoch 20/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.6557 - F1: 0.8012 - val_loss: 1.0958 - val_F1: 0.6100\n",
      "Epoch 21/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.6272 - F1: 0.8108 - val_loss: 1.0862 - val_F1: 0.6097\n",
      "Epoch 22/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.5965 - F1: 0.8212 - val_loss: 1.1081 - val_F1: 0.6023\n",
      "Epoch 23/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.5784 - F1: 0.8270 - val_loss: 1.0968 - val_F1: 0.6073\n",
      "Epoch 24/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.5553 - F1: 0.8343 - val_loss: 1.1158 - val_F1: 0.6036\n",
      "Epoch 25/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.5359 - F1: 0.8407 - val_loss: 1.0903 - val_F1: 0.6132\n",
      "Epoch 26/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.5237 - F1: 0.8444 - val_loss: 1.1029 - val_F1: 0.5980\n",
      "Epoch 27/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.5017 - F1: 0.8516 - val_loss: 1.1022 - val_F1: 0.6111\n",
      "Epoch 28/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.4865 - F1: 0.8564 - val_loss: 1.1032 - val_F1: 0.6126\n",
      "Epoch 29/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.4728 - F1: 0.8608 - val_loss: 1.1150 - val_F1: 0.6160\n",
      "Epoch 30/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.4580 - F1: 0.8655 - val_loss: 1.1394 - val_F1: 0.6042\n",
      "Epoch 31/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.4449 - F1: 0.8699 - val_loss: 1.1007 - val_F1: 0.6144\n",
      "Epoch 32/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.4324 - F1: 0.8739 - val_loss: 1.1129 - val_F1: 0.6182\n",
      "Epoch 33/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.4210 - F1: 0.8773 - val_loss: 1.1102 - val_F1: 0.6153\n",
      "Epoch 34/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.4067 - F1: 0.8820 - val_loss: 1.1201 - val_F1: 0.6085\n",
      "Epoch 35/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3958 - F1: 0.8856 - val_loss: 1.1118 - val_F1: 0.6157\n",
      "Epoch 36/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3852 - F1: 0.8890 - val_loss: 1.1272 - val_F1: 0.6133\n",
      "Epoch 37/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3785 - F1: 0.8907 - val_loss: 1.1378 - val_F1: 0.6107\n",
      "Epoch 38/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3706 - F1: 0.8933 - val_loss: 1.1491 - val_F1: 0.6085\n",
      "Epoch 39/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3598 - F1: 0.8966 - val_loss: 1.1311 - val_F1: 0.6183\n",
      "Epoch 40/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3525 - F1: 0.8991 - val_loss: 1.1136 - val_F1: 0.6266\n",
      "Epoch 41/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3421 - F1: 0.9025 - val_loss: 1.1240 - val_F1: 0.6121\n",
      "Epoch 42/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3380 - F1: 0.9035 - val_loss: 1.1547 - val_F1: 0.6148\n",
      "Epoch 43/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3315 - F1: 0.9056 - val_loss: 1.1325 - val_F1: 0.6098\n",
      "Epoch 44/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3247 - F1: 0.9076 - val_loss: 1.1314 - val_F1: 0.6122\n",
      "Epoch 45/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3151 - F1: 0.9107 - val_loss: 1.1458 - val_F1: 0.6167\n",
      "Epoch 46/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3103 - F1: 0.9122 - val_loss: 1.1336 - val_F1: 0.6267\n",
      "Epoch 47/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.3043 - F1: 0.9140 - val_loss: 1.1418 - val_F1: 0.6132\n",
      "Epoch 48/50\n",
      "144/144 [==============================] - 8s 57ms/step - loss: 0.2982 - F1: 0.9159 - val_loss: 1.1311 - val_F1: 0.6121\n",
      "Epoch 49/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.2947 - F1: 0.9168 - val_loss: 1.1392 - val_F1: 0.6108\n",
      "Epoch 50/50\n",
      "144/144 [==============================] - 8s 53ms/step - loss: 0.2884 - F1: 0.9188 - val_loss: 1.1551 - val_F1: 0.6197\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train, validation_data=(X_val, Y_val), batch_size=32,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HPCL\\anaconda3\\envs\\torch_env\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save('Deepwatermap_github_sentinel_2dil-ndwi.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Name</th>\n",
       "      <th>IoU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Positive Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0850</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.453175</td>\n",
       "      <td>0.647053</td>\n",
       "      <td>0.601980</td>\n",
       "      <td>0.623703</td>\n",
       "      <td>0.989133</td>\n",
       "      <td>0.010867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0850</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.453175</td>\n",
       "      <td>0.647053</td>\n",
       "      <td>0.601980</td>\n",
       "      <td>0.623703</td>\n",
       "      <td>0.989133</td>\n",
       "      <td>0.010867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0845</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.453160</td>\n",
       "      <td>0.646932</td>\n",
       "      <td>0.602058</td>\n",
       "      <td>0.623689</td>\n",
       "      <td>0.989126</td>\n",
       "      <td>0.010874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0840</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.453149</td>\n",
       "      <td>0.646820</td>\n",
       "      <td>0.602136</td>\n",
       "      <td>0.623679</td>\n",
       "      <td>0.989119</td>\n",
       "      <td>0.010881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0900</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.453149</td>\n",
       "      <td>0.648048</td>\n",
       "      <td>0.601075</td>\n",
       "      <td>0.623679</td>\n",
       "      <td>0.989196</td>\n",
       "      <td>0.010804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold                                Name       IoU  Precision  \\\n",
       "40     0.0850  DWM Trained BCE 50 Epochs Sentinel  0.453175   0.647053   \n",
       "27     0.0850  DWM Trained BCE 50 Epochs Sentinel  0.453175   0.647053   \n",
       "39     0.0845  DWM Trained BCE 50 Epochs Sentinel  0.453160   0.646932   \n",
       "38     0.0840  DWM Trained BCE 50 Epochs Sentinel  0.453149   0.646820   \n",
       "28     0.0900  DWM Trained BCE 50 Epochs Sentinel  0.453149   0.648048   \n",
       "\n",
       "      Recall   F-Score  True Negative Rate  False Positive Rate  \n",
       "40  0.601980  0.623703            0.989133             0.010867  \n",
       "27  0.601980  0.623703            0.989133             0.010867  \n",
       "39  0.602058  0.623689            0.989126             0.010874  \n",
       "38  0.602136  0.623679            0.989119             0.010881  \n",
       "28  0.601075  0.623679            0.989196             0.010804  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test).squeeze()\n",
    "dict_1 = best_f_score('DWM Trained BCE 50 Epochs Sentinel', Y_test, predictions)\n",
    "df_rotate = pd.DataFrame(dict_1)\n",
    "df_rotate = df_rotate.sort_values(by=['F-Score'], ascending=False)\n",
    "df_rotate.to_csv(r'F-score DWM.csv', mode='a')\n",
    "df_rotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5805885332085843"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score(Y_test.reshape(-1), predictions.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HPCL\\AppData\\Local\\Temp/ipykernel_13760/890076540.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_train = (X_train[...,1]-X_train[...,3])/(X_train[...,1]+X_train[...,3])\n",
      "C:\\Users\\HPCL\\AppData\\Local\\Temp/ipykernel_13760/890076540.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_test  = (X_test[...,1] -X_test[...,3]) /(X_test[...,1]+X_test[...,3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4500, 500, 2000, 4500, 500, 2000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_train_4500_30m_res.npy\")\n",
    "X_val   = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_val_500_30m_res.npy\")\n",
    "X_test  = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_test_2000_30m_res.npy\")\n",
    "\n",
    "Y_train = (X_train[...,1]-X_train[...,3])/(X_train[...,1]+X_train[...,3])\n",
    "Y_val   = (X_val[...,1]  -X_val[...,3])  /(X_val[...,1]+X_val[...,3])\n",
    "Y_test  = (X_test[...,1] -X_test[...,3]) /(X_test[...,1]+X_test[...,3])\n",
    "\n",
    "Y_train = ((Y_train<1.)*1).astype('float32')\n",
    "Y_val   = ((Y_val<1.)*1).astype('float32')\n",
    "Y_test  = ((Y_test<1.)*1).astype('float32')\n",
    "\n",
    "X_train = X_train[...,2::-1].copy()\n",
    "X_val   = X_val[...,2::-1].copy()\n",
    "X_test  = X_test[...,2::-1].copy()\n",
    "\n",
    "X_train = X_train - X_train.min(axis=(1,2), keepdims=True) \n",
    "X_val   = X_val  - X_val.min(axis=(1,2), keepdims=True)\n",
    "X_test  = X_test - X_test.min(axis=(1,2), keepdims=True) \n",
    "\n",
    "X_train = X_train / X_train.max(axis=(1,2), keepdims=True) \n",
    "X_val   = X_val  / X_val.max(axis=(1,2), keepdims=True)\n",
    "X_test  = X_test / X_test.max(axis=(1,2), keepdims=True) \n",
    "\n",
    "len(X_train), len(X_val), len(X_test), len(Y_train), len(Y_val), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Get Contours ##########################\n",
    "Y_train = np.array([binary_dilation(mask)-mask for mask in Y_train ], dtype='float32')[...,np.newaxis]\n",
    "Y_val   = np.array([binary_dilation(mask)-mask for mask in Y_val], dtype='float32')[...,np.newaxis]\n",
    "Y_test  = np.array([binary_dilation(mask)-mask for mask in Y_test], dtype='float32')[...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(y_true,y_pred):\n",
    "    threshold = 0.5\n",
    "\n",
    "    y_true = tf.reshape(y_true,[-1])\n",
    "    y_pred = tf.reshape(y_pred,[-1])\n",
    "    y_pred = (y_pred>threshold)\n",
    "    y_pred = tf.cast(y_pred,dtype=tf.float32)\n",
    "\n",
    "    tp = K.sum(y_true*(y_pred))\n",
    "    tn = K.sum((1-y_true)*((1-y_pred)))\n",
    "    fp = K.sum((1-y_true)*(y_pred))\n",
    "    fn = K.sum((y_true)*((1-y_pred)))\n",
    "\n",
    "    pr  = ((tp+1.)/(tp+fp+1.))\n",
    "    rec = ((tp+1.)/(tp+fn+1.))\n",
    "    f1  = ((2*pr*rec)/(pr+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) *     (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def loss_kaggle(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(11, 11), strides=(1, 1), padding='same', pool_mode='avg', data_format=\"channels_last\")\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    \n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) +\\\n",
    "    weighted_dice_loss(y_true, y_pred, weight) +\\\n",
    "    IoU_loss(y_true, y_pred, weight)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def IoU(y_true, y_pred, weight):\n",
    "    weight = weight*weight\n",
    "    intersection = y_true*y_pred\n",
    "    not_true     = 1 - y_true\n",
    "    union        = y_true + (not_true * y_pred)\n",
    "    score        = (K.sum(weight * intersection)) / (K.sum(weight * union))\n",
    "    return score\n",
    "\n",
    "\n",
    "# IoU as a loss function\n",
    "def IoU_loss(y_true, y_pred, weight):\n",
    "    return 1 - IoU(y_true, y_pred, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, None, None,   12          ['input_1[0][0]']                \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, None, None,   16         ['conv2d[0][0]']                 \n",
      " alization)                     4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, None, None,   1600        ['batch_normalization[0][0]']    \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, None, None,   64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   16)                                                               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, None,   0           ['batch_normalization_1[0][0]']  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, None, None,   2304        ['activation[0][0]']             \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, None, None,   64         ['conv2d_2[0][0]']               \n",
      " rmalization)                   16)                                                               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, None,   0           ['batch_normalization_2[0][0]']  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, None, None,   0           ['activation[0][0]',             \n",
      "                                16)                               'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, None, None,   25600       ['add[0][0]']                    \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, None, None,   256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, None,   0           ['batch_normalization_3[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, None, None,   36864       ['activation_2[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, None, None,   256        ['conv2d_4[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, None, None,   0           ['batch_normalization_4[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, None, None,   0           ['activation_2[0][0]',           \n",
      "                                64)                               'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, None, None,   409600      ['add_1[0][0]']                  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, None, None,   1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                   256)                                                              \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, None, None,   0           ['batch_normalization_5[0][0]']  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, None, None,   589824      ['activation_4[0][0]']           \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, None, None,   1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                   256)                                                              \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, None, None,   0           ['batch_normalization_6[0][0]']  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, None, None,   0           ['activation_4[0][0]',           \n",
      "                                256)                              'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, None, None,   6553600     ['add_2[0][0]']                  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, None, None,   4096       ['conv2d_7[0][0]']               \n",
      " rmalization)                   1024)                                                             \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, None, None,   0           ['batch_normalization_7[0][0]']  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, None, None,   9437184     ['activation_6[0][0]']           \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, None, None,   4096       ['conv2d_8[0][0]']               \n",
      " rmalization)                   1024)                                                             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, None, None,   0           ['batch_normalization_8[0][0]']  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, None, None,   0           ['activation_6[0][0]',           \n",
      "                                1024)                             'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, None, None,   9437184     ['add_3[0][0]']                  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, None, None,   4096       ['conv2d_9[0][0]']               \n",
      " rmalization)                   1024)                                                             \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, None, None,   0           ['batch_normalization_9[0][0]']  \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, None, None,   9437184     ['activation_8[0][0]']           \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, None, None,   4096       ['conv2d_10[0][0]']              \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, None, None,   0           ['batch_normalization_10[0][0]'] \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, None, None,   0           ['activation_8[0][0]',           \n",
      "                                1024)                             'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, None, None,   0           ['add_4[0][0]',                  \n",
      "                                1024)                             'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, None, None,   0           ['add_5[0][0]']                  \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, None, None,   589824      ['lambda[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, None, None,   1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, None, None,   0           ['batch_normalization_11[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, None, None,   589824      ['activation_10[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, None, None,   1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, None, None,   0           ['batch_normalization_12[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, None, None,   0           ['activation_10[0][0]',          \n",
      "                                256)                              'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, None, None,   0           ['add_6[0][0]',                  \n",
      "                                256)                              'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, None, None,   0           ['add_7[0][0]']                  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, None, None,   36864       ['lambda_1[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, None, None,   256        ['conv2d_13[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, None, None,   0           ['batch_normalization_13[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, None, None,   36864       ['activation_12[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, None, None,   256        ['conv2d_14[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, None, None,   0           ['batch_normalization_14[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, None, None,   0           ['activation_12[0][0]',          \n",
      "                                64)                               'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, None, None,   0           ['add_8[0][0]',                  \n",
      "                                64)                               'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, None, None,   0           ['add_9[0][0]']                  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, None, None,   2304        ['lambda_2[0][0]']               \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, None, None,   64         ['conv2d_15[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, None, None,   0           ['batch_normalization_15[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, None, None,   2304        ['activation_14[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, None, None,   64         ['conv2d_16[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, None, None,   0           ['batch_normalization_16[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, None, None,   0           ['activation_14[0][0]',          \n",
      "                                16)                               'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, None, None,   0           ['add_10[0][0]',                 \n",
      "                                16)                               'add[0][0]']                    \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              (None, None, None,   0           ['add_11[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, None, None,   144         ['lambda_3[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, None, None,   16         ['conv2d_17[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, None, None,   0           ['batch_normalization_17[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, None, None,   144         ['activation_16[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, None, None,   16         ['conv2d_18[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, None, None,   0           ['batch_normalization_18[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, None, None,   0           ['activation_16[0][0]',          \n",
      "                                4)                                'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, None, None,   0           ['add_12[0][0]',                 \n",
      "                                4)                                'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, None, None,   4           ['add_13[0][0]']                 \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, None, None,   4          ['conv2d_19[0][0]']              \n",
      " ormalization)                  1)                                                                \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, None, None,   0           ['batch_normalization_19[0][0]'] \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 37,211,044\n",
      "Trainable params: 37,200,138\n",
      "Non-trainable params: 10,906\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = deepwatermap.model()\n",
    "opt   = Adam(learning_rate=0.003)\n",
    "model.compile(optimizer=opt, loss= loss_kaggle, metrics=[F1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141/141 [==============================] - 19s 56ms/step - loss: 2.4264 - F1: 0.1217 - val_loss: 2.2154 - val_F1: 0.2629\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 7s 50ms/step - loss: 2.1863 - F1: 0.2768 - val_loss: 2.0833 - val_F1: 0.3605\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 2.0086 - F1: 0.3687 - val_loss: 1.9922 - val_F1: 0.3910\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 7s 50ms/step - loss: 1.8636 - F1: 0.4130 - val_loss: 1.8240 - val_F1: 0.4871\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.7335 - F1: 0.4513 - val_loss: 1.6873 - val_F1: 0.4430\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.6183 - F1: 0.4833 - val_loss: 1.5610 - val_F1: 0.4498\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.5173 - F1: 0.5075 - val_loss: 1.4923 - val_F1: 0.5319\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.4337 - F1: 0.5248 - val_loss: 1.4129 - val_F1: 0.5316\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.3573 - F1: 0.5412 - val_loss: 1.3696 - val_F1: 0.5354\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.2860 - F1: 0.5632 - val_loss: 1.3080 - val_F1: 0.4763\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.2329 - F1: 0.5723 - val_loss: 1.2344 - val_F1: 0.5674\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.1800 - F1: 0.5895 - val_loss: 1.2249 - val_F1: 0.5414\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.1333 - F1: 0.6039 - val_loss: 1.1836 - val_F1: 0.5568\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 1.0915 - F1: 0.6166 - val_loss: 1.1528 - val_F1: 0.5655\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 1.0487 - F1: 0.6316 - val_loss: 1.1587 - val_F1: 0.5654\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 1.0113 - F1: 0.6434 - val_loss: 1.1437 - val_F1: 0.5692\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.9690 - F1: 0.6594 - val_loss: 1.1375 - val_F1: 0.5767\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.9355 - F1: 0.6714 - val_loss: 1.1448 - val_F1: 0.5588\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.8994 - F1: 0.6849 - val_loss: 1.1187 - val_F1: 0.5735\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.8592 - F1: 0.7003 - val_loss: 1.1148 - val_F1: 0.5694\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.8263 - F1: 0.7126 - val_loss: 1.1353 - val_F1: 0.5650\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.7985 - F1: 0.7229 - val_loss: 1.1595 - val_F1: 0.5522\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.7657 - F1: 0.7360 - val_loss: 1.1408 - val_F1: 0.5592\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.7389 - F1: 0.7458 - val_loss: 1.1311 - val_F1: 0.5593\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.7069 - F1: 0.7581 - val_loss: 1.1315 - val_F1: 0.5558\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.6848 - F1: 0.7664 - val_loss: 1.1287 - val_F1: 0.5612\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.6640 - F1: 0.7741 - val_loss: 1.1630 - val_F1: 0.5516\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.6445 - F1: 0.7816 - val_loss: 1.1303 - val_F1: 0.5591\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.6249 - F1: 0.7888 - val_loss: 1.1441 - val_F1: 0.5529\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.6034 - F1: 0.7968 - val_loss: 1.1486 - val_F1: 0.5550\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.5932 - F1: 0.8006 - val_loss: 1.1520 - val_F1: 0.5535\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.5774 - F1: 0.8065 - val_loss: 1.1483 - val_F1: 0.5544\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.5571 - F1: 0.8139 - val_loss: 1.1418 - val_F1: 0.5560\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.5432 - F1: 0.8188 - val_loss: 1.1611 - val_F1: 0.5491\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.5320 - F1: 0.8232 - val_loss: 1.1544 - val_F1: 0.5529\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.5153 - F1: 0.8295 - val_loss: 1.1489 - val_F1: 0.5526\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.5062 - F1: 0.8325 - val_loss: 1.1479 - val_F1: 0.5579\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.4952 - F1: 0.8368 - val_loss: 1.1557 - val_F1: 0.5530\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.4880 - F1: 0.8388 - val_loss: 1.1532 - val_F1: 0.5503\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.4804 - F1: 0.8416 - val_loss: 1.1568 - val_F1: 0.5554\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.4719 - F1: 0.8445 - val_loss: 1.1473 - val_F1: 0.5566\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.4544 - F1: 0.8510 - val_loss: 1.1577 - val_F1: 0.5527\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.4477 - F1: 0.8532 - val_loss: 1.1712 - val_F1: 0.5445\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.4358 - F1: 0.8579 - val_loss: 1.1624 - val_F1: 0.5506\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.4358 - F1: 0.8575 - val_loss: 1.1552 - val_F1: 0.5532\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.4257 - F1: 0.8615 - val_loss: 1.1532 - val_F1: 0.5524\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.4165 - F1: 0.8645 - val_loss: 1.1683 - val_F1: 0.5481\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.4141 - F1: 0.8653 - val_loss: 1.1700 - val_F1: 0.5491\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.4084 - F1: 0.8677 - val_loss: 1.1641 - val_F1: 0.5512\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.3991 - F1: 0.8708 - val_loss: 1.1824 - val_F1: 0.5463\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train, validation_data=(X_val, Y_val), batch_size=32,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Name</th>\n",
       "      <th>IoU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Positive Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>DWM Landsat</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.527954</td>\n",
       "      <td>0.592422</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.994260</td>\n",
       "      <td>0.005740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>DWM Landsat</td>\n",
       "      <td>0.387265</td>\n",
       "      <td>0.525991</td>\n",
       "      <td>0.594870</td>\n",
       "      <td>0.558314</td>\n",
       "      <td>0.994191</td>\n",
       "      <td>0.005809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>DWM Landsat</td>\n",
       "      <td>0.387186</td>\n",
       "      <td>0.523639</td>\n",
       "      <td>0.597720</td>\n",
       "      <td>0.558232</td>\n",
       "      <td>0.994107</td>\n",
       "      <td>0.005892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0035</td>\n",
       "      <td>DWM Landsat</td>\n",
       "      <td>0.387035</td>\n",
       "      <td>0.520802</td>\n",
       "      <td>0.601096</td>\n",
       "      <td>0.558075</td>\n",
       "      <td>0.994006</td>\n",
       "      <td>0.005994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>DWM Landsat</td>\n",
       "      <td>0.386866</td>\n",
       "      <td>0.517317</td>\n",
       "      <td>0.605392</td>\n",
       "      <td>0.557900</td>\n",
       "      <td>0.993879</td>\n",
       "      <td>0.006121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold         Name       IoU  Precision    Recall   F-Score  \\\n",
       "21     0.0050  DWM Landsat  0.387283   0.527954  0.592422  0.558333   \n",
       "39     0.0045  DWM Landsat  0.387265   0.525991  0.594870  0.558314   \n",
       "38     0.0040  DWM Landsat  0.387186   0.523639  0.597720  0.558232   \n",
       "37     0.0035  DWM Landsat  0.387035   0.520802  0.601096  0.558075   \n",
       "36     0.0030  DWM Landsat  0.386866   0.517317  0.605392  0.557900   \n",
       "\n",
       "    True Negative Rate  False Positive Rate  \n",
       "21            0.994260             0.005740  \n",
       "39            0.994191             0.005809  \n",
       "38            0.994107             0.005892  \n",
       "37            0.994006             0.005994  \n",
       "36            0.993879             0.006121  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test).squeeze()\n",
    "dict_1 = best_f_score('DWM Landsat', Y_test, predictions)\n",
    "df = pd.DataFrame(dict_1)\n",
    "df = df.sort_values(by=['F-Score'], ascending=False)\n",
    "AP = average_precision_score(Y_test.squeeze().reshape(-1), predictions.reshape(-1))\n",
    "df.to_csv(r'F-score DWM.csv', mode='a')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43775317534327784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(Y_test.squeeze().reshape(-1), predictions.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat + Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HPCL\\AppData\\Local\\Temp/ipykernel_12952/466507815.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_train_L         = (X_train_L[...,1]-X_train_L[...,3])/(X_train_L[...,1]+X_train_L[...,3])\n",
      "C:\\Users\\HPCL\\AppData\\Local\\Temp/ipykernel_12952/466507815.py:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_test_L          = (X_test_L[...,1]-X_test_L[...,3])/(X_test_L[...,1]+X_test_L[...,3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9108, 1013, 4053, 9108, 1013, 4053)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(49)\n",
    "pop = np.arange(5121)\n",
    "sample_train = np.random.choice(pop, 4608, replace=False)\n",
    "sample_test  = np.delete(pop, sample_train)\n",
    "len(sample_train), len(sample_test)\n",
    "\n",
    "X      = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Sentinel uint16 Data 0%water and 0%land exclude\\X_train_sentinel_6_channles_5121.npy\")\n",
    "X_test_S = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Sentinel uint16 Data 0%water and 0%land exclude\\X_test_sentinel_6_channles_2053.npy\")\n",
    "X_train_S= X[sample_train]\n",
    "X_val_S  = X[sample_test]\n",
    "\n",
    "Y_train_S         = (X_train_S[...,1]-X_train_S[...,3])/(X_train_S[...,1]+X_train_S[...,3])\n",
    "Y_val_S           = (X_val_S[...,1]-X_val_S[...,3])/(X_val_S[...,1]+X_val_S[...,3])\n",
    "Y_test_S          = (X_test_S[...,1]-X_test_S[...,3])/(X_test_S[...,1]+X_test_S[...,3])\n",
    "\n",
    "Y_train_S         = ((Y_train_S<1.)*1).astype('float32')\n",
    "Y_val_S           = ((Y_val_S<1.)*1).astype('float32')\n",
    "Y_test_S          = ((Y_test_S<1.)*1).astype('float32')\n",
    "\n",
    "X_train_S         = X_train_S[...,2::-1].copy()\n",
    "X_val_S           = X_val_S[...,2::-1].copy()\n",
    "X_test_S          = X_test_S[...,2::-1].copy()\n",
    "\n",
    "X_train_S         = np.clip(X_train_S, 0, 3558) \n",
    "X_val_S           = np.clip(X_val_S, 0, 3558)\n",
    "X_test_S          = np.clip(X_test_S, 0, 3558) \n",
    "\n",
    "X_train_S         = X_train_S - X_train_S.min(axis=(1,2), keepdims=True) \n",
    "X_val_S           = X_val_S   - X_val_S.min(axis=(1,2), keepdims=True)\n",
    "X_test_S          = X_test_S  - X_test_S.min(axis=(1,2), keepdims=True) \n",
    "\n",
    "X_train_S         = X_train_S / X_train_S.max(axis=(1,2), keepdims=True) \n",
    "X_val_S           = X_val_S   / X_val_S.max(axis=(1,2), keepdims=True)\n",
    "X_test_S          = X_test_S  / X_test_S.max(axis=(1,2), keepdims=True) \n",
    "\n",
    "X_train_L = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_train_4500_30m_res.npy\")\n",
    "X_val_L   = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_val_500_30m_res.npy\")\n",
    "X_test_L  = np.load(r\"C:\\Users\\HPCL\\OneDrive - University of New Orleans\\Documents\\Research\\Year 1\\Paper Experiments\\Data\\Landsat 30m Resolution\\X_test_2000_30m_res.npy\")\n",
    "\n",
    "Y_train_L         = (X_train_L[...,1]-X_train_L[...,3])/(X_train_L[...,1]+X_train_L[...,3])\n",
    "Y_val_L           = (X_val_L[...,1]-X_val_L[...,3])/(X_val_L[...,1]+X_val_L[...,3])\n",
    "Y_test_L          = (X_test_L[...,1]-X_test_L[...,3])/(X_test_L[...,1]+X_test_L[...,3])\n",
    "\n",
    "Y_train_L         = ((Y_train_L<1.)*1).astype('float32')\n",
    "Y_val_L           = ((Y_val_L<1.)*1).astype('float32')\n",
    "Y_test_L          = ((Y_test_L<1.)*1).astype('float32')\n",
    "\n",
    "X_train_L         = X_train_L[...,2::-1].copy()\n",
    "X_val_L           = X_val_L[...,2::-1].copy()\n",
    "X_test_L          = X_test_L[...,2::-1].copy()\n",
    "\n",
    "X_train_L         = X_train_L - X_train_L.min(axis=(1,2), keepdims=True) \n",
    "X_val_L           = X_val_L  - X_val_L.min(axis=(1,2), keepdims=True)\n",
    "X_test_L          = X_test_L - X_test_L.min(axis=(1,2), keepdims=True) \n",
    "\n",
    "X_train_L         = X_train_L / X_train_L.max(axis=(1,2), keepdims=True) \n",
    "X_val_L           = X_val_L  / X_val_L.max(axis=(1,2), keepdims=True)\n",
    "X_test_L          = X_test_L / X_test_L.max(axis=(1,2), keepdims=True) \n",
    "\n",
    "X_train = np.concatenate((X_train_L, X_train_S), axis=0)\n",
    "X_val   = np.concatenate((X_val_L, X_val_S), axis=0)\n",
    "X_test  = np.concatenate((X_test_L, X_test_S), axis=0)\n",
    "\n",
    "Y_train = np.concatenate((Y_train_L, Y_train_S), axis=0)\n",
    "Y_val   = np.concatenate((Y_val_L, Y_val_S), axis=0)\n",
    "Y_test  = np.concatenate((Y_test_L, Y_test_S), axis=0)\n",
    "\n",
    "len(X_train), len(X_val), len(X_test), len(Y_train), len(Y_val), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Get Contours ##########################\n",
    "Y_train = np.array([binary_dilation(mask)-mask for mask in Y_train ], dtype='float32')[...,np.newaxis]\n",
    "Y_val   = np.array([binary_dilation(mask)-mask for mask in Y_val], dtype='float32')[...,np.newaxis]\n",
    "Y_test  = np.array([binary_dilation(mask)-mask for mask in Y_test], dtype='float32')[...,np.newaxis]\n",
    "\n",
    "Y_train_L = np.array([binary_dilation(mask)-mask for mask in Y_train_L ], dtype='float32')[...,np.newaxis]\n",
    "Y_val_L   = np.array([binary_dilation(mask)-mask for mask in Y_val_L], dtype='float32')[...,np.newaxis]\n",
    "Y_test_L  = np.array([binary_dilation(mask)-mask for mask in Y_test_L], dtype='float32')[...,np.newaxis]\n",
    "\n",
    "Y_train_S = np.array([binary_dilation(mask)-mask for mask in Y_train_S], dtype='float32')[...,np.newaxis]\n",
    "Y_val_S   = np.array([binary_dilation(mask)-mask for mask in Y_val_S], dtype='float32')[...,np.newaxis]\n",
    "Y_test_S  = np.array([binary_dilation(mask)-mask for mask in Y_test_S], dtype='float32')[...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(y_true,y_pred):\n",
    "    threshold = 0.5\n",
    "\n",
    "    y_true = tf.reshape(y_true,[-1])\n",
    "    y_pred = tf.reshape(y_pred,[-1])\n",
    "    y_pred = (y_pred>threshold)\n",
    "    y_pred = tf.cast(y_pred,dtype=tf.float32)\n",
    "\n",
    "    tp = K.sum(y_true*(y_pred))\n",
    "    tn = K.sum((1-y_true)*((1-y_pred)))\n",
    "    fp = K.sum((1-y_true)*(y_pred))\n",
    "    fn = K.sum((y_true)*((1-y_pred)))\n",
    "\n",
    "    pr  = ((tp+1.)/(tp+fp+1.))\n",
    "    rec = ((tp+1.)/(tp+fn+1.))\n",
    "    f1  = ((2*pr*rec)/(pr+rec))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) *     (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def loss_kaggle(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(11, 11), strides=(1, 1), padding='same', pool_mode='avg', data_format=\"channels_last\")\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    \n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) +\\\n",
    "    weighted_dice_loss(y_true, y_pred, weight) +\\\n",
    "    IoU_loss(y_true, y_pred, weight)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def IoU(y_true, y_pred, weight):\n",
    "    weight = weight*weight\n",
    "    intersection = y_true*y_pred\n",
    "    not_true     = 1 - y_true\n",
    "    union        = y_true + (not_true * y_pred)\n",
    "    score        = (K.sum(weight * intersection)) / (K.sum(weight * union))\n",
    "    return score\n",
    "\n",
    "\n",
    "# IoU as a loss function\n",
    "def IoU_loss(y_true, y_pred, weight):\n",
    "    return 1 - IoU(y_true, y_pred, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, None, None,   12          ['input_2[0][0]']                \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, None, None,   16         ['conv2d_20[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, None, None,   1600        ['batch_normalization_20[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, None, None,   64         ['conv2d_21[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, None, None,   0           ['batch_normalization_21[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, None, None,   2304        ['activation_19[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, None, None,   64         ['conv2d_22[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, None, None,   0           ['batch_normalization_22[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, None, None,   0           ['activation_19[0][0]',          \n",
      "                                16)                               'activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, None, None,   25600       ['add_14[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, None, None,   256        ['conv2d_23[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, None, None,   0           ['batch_normalization_23[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, None, None,   36864       ['activation_21[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, None, None,   256        ['conv2d_24[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, None, None,   0           ['batch_normalization_24[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, None, None,   0           ['activation_21[0][0]',          \n",
      "                                64)                               'activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, None, None,   409600      ['add_15[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, None, None,   1024       ['conv2d_25[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, None, None,   0           ['batch_normalization_25[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, None, None,   589824      ['activation_23[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, None, None,   1024       ['conv2d_26[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, None, None,   0           ['batch_normalization_26[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, None, None,   0           ['activation_23[0][0]',          \n",
      "                                256)                              'activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, None, None,   6553600     ['add_16[0][0]']                 \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, None, None,   4096       ['conv2d_27[0][0]']              \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, None, None,   0           ['batch_normalization_27[0][0]'] \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, None, None,   9437184     ['activation_25[0][0]']          \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, None, None,   4096       ['conv2d_28[0][0]']              \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, None, None,   0           ['batch_normalization_28[0][0]'] \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, None, None,   0           ['activation_25[0][0]',          \n",
      "                                1024)                             'activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, None, None,   9437184     ['add_17[0][0]']                 \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, None, None,   4096       ['conv2d_29[0][0]']              \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, None, None,   0           ['batch_normalization_29[0][0]'] \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, None, None,   9437184     ['activation_27[0][0]']          \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, None, None,   4096       ['conv2d_30[0][0]']              \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, None, None,   0           ['batch_normalization_30[0][0]'] \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, None, None,   0           ['activation_27[0][0]',          \n",
      "                                1024)                             'activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, None, None,   0           ['add_18[0][0]',                 \n",
      "                                1024)                             'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, None, None,   0           ['add_19[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, None, None,   589824      ['lambda_4[0][0]']               \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, None, None,   1024       ['conv2d_31[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, None, None,   0           ['batch_normalization_31[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, None, None,   589824      ['activation_29[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, None, None,   1024       ['conv2d_32[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, None, None,   0           ['batch_normalization_32[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, None, None,   0           ['activation_29[0][0]',          \n",
      "                                256)                              'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, None, None,   0           ['add_20[0][0]',                 \n",
      "                                256)                              'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              (None, None, None,   0           ['add_21[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, None, None,   36864       ['lambda_5[0][0]']               \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, None, None,   256        ['conv2d_33[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, None, None,   0           ['batch_normalization_33[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, None, None,   36864       ['activation_31[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, None, None,   256        ['conv2d_34[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, None, None,   0           ['batch_normalization_34[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, None, None,   0           ['activation_31[0][0]',          \n",
      "                                64)                               'activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, None, None,   0           ['add_22[0][0]',                 \n",
      "                                64)                               'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, None, None,   0           ['add_23[0][0]']                 \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, None, None,   2304        ['lambda_6[0][0]']               \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, None, None,   64         ['conv2d_35[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, None, None,   0           ['batch_normalization_35[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, None, None,   2304        ['activation_33[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, None, None,   64         ['conv2d_36[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, None, None,   0           ['batch_normalization_36[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, None, None,   0           ['activation_33[0][0]',          \n",
      "                                16)                               'activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, None, None,   0           ['add_24[0][0]',                 \n",
      "                                16)                               'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, None, None,   0           ['add_25[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, None, None,   144         ['lambda_7[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, None, None,   16         ['conv2d_37[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, None, None,   0           ['batch_normalization_37[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, None, None,   144         ['activation_35[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, None, None,   16         ['conv2d_38[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, None, None,   0           ['batch_normalization_38[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, None, None,   0           ['activation_35[0][0]',          \n",
      "                                4)                                'activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, None, None,   0           ['add_26[0][0]',                 \n",
      "                                4)                                'batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, None, None,   4           ['add_27[0][0]']                 \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, None, None,   4          ['conv2d_39[0][0]']              \n",
      " ormalization)                  1)                                                                \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, None, None,   0           ['batch_normalization_39[0][0]'] \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 37,211,044\n",
      "Trainable params: 37,200,138\n",
      "Non-trainable params: 10,906\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = deepwatermap.model()\n",
    "opt   = Adam(learning_rate=0.003)\n",
    "model.compile(optimizer=opt, loss= loss_kaggle, metrics=[F1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "285/285 [==============================] - 31s 54ms/step - loss: 2.3314 - F1: 0.1547 - val_loss: 2.0838 - val_F1: 0.3087\n",
      "Epoch 2/50\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 1.9650 - F1: 0.3399 - val_loss: 1.8376 - val_F1: 0.4008\n",
      "Epoch 3/50\n",
      "285/285 [==============================] - 14s 51ms/step - loss: 1.7212 - F1: 0.4179 - val_loss: 1.6166 - val_F1: 0.4767\n",
      "Epoch 4/50\n",
      "285/285 [==============================] - 14s 51ms/step - loss: 1.5457 - F1: 0.4609 - val_loss: 1.5984 - val_F1: 0.3946\n",
      "Epoch 5/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.4214 - F1: 0.4902 - val_loss: 1.3783 - val_F1: 0.4958\n",
      "Epoch 6/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.3376 - F1: 0.5079 - val_loss: 1.2939 - val_F1: 0.5190\n",
      "Epoch 7/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.2748 - F1: 0.5238 - val_loss: 1.2552 - val_F1: 0.5271\n",
      "Epoch 8/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.2312 - F1: 0.5351 - val_loss: 1.2374 - val_F1: 0.5255\n",
      "Epoch 9/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.1936 - F1: 0.5475 - val_loss: 1.1919 - val_F1: 0.5346\n",
      "Epoch 10/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.1659 - F1: 0.5571 - val_loss: 1.1938 - val_F1: 0.5453\n",
      "Epoch 11/50\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 1.1398 - F1: 0.5669 - val_loss: 1.2002 - val_F1: 0.5242\n",
      "Epoch 12/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.1189 - F1: 0.5746 - val_loss: 1.1783 - val_F1: 0.5461\n",
      "Epoch 13/50\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 1.0883 - F1: 0.5881 - val_loss: 1.1887 - val_F1: 0.5026\n",
      "Epoch 14/50\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 1.0685 - F1: 0.5960 - val_loss: 1.2106 - val_F1: 0.5305\n",
      "Epoch 15/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.0448 - F1: 0.6067 - val_loss: 1.1603 - val_F1: 0.5408\n",
      "Epoch 16/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 1.0179 - F1: 0.6191 - val_loss: 1.1714 - val_F1: 0.5413\n",
      "Epoch 17/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 0.9936 - F1: 0.6294 - val_loss: 1.1767 - val_F1: 0.5431\n",
      "Epoch 18/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 0.9747 - F1: 0.6384 - val_loss: 1.1614 - val_F1: 0.5434\n",
      "Epoch 19/50\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 0.9457 - F1: 0.6511 - val_loss: 1.1872 - val_F1: 0.5389\n",
      "Epoch 20/50\n",
      "285/285 [==============================] - 14s 51ms/step - loss: 0.9270 - F1: 0.6593 - val_loss: 1.2013 - val_F1: 0.5349\n",
      "Epoch 21/50\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 0.9042 - F1: 0.6696 - val_loss: 1.2017 - val_F1: 0.5330\n",
      "Epoch 22/50\n",
      "285/285 [==============================] - 14s 50ms/step - loss: 0.8851 - F1: 0.6781 - val_loss: 1.1886 - val_F1: 0.5365\n",
      "Epoch 23/50\n",
      "285/285 [==============================] - 14s 51ms/step - loss: 0.8607 - F1: 0.6890 - val_loss: 1.2000 - val_F1: 0.5311\n",
      "Epoch 24/50\n",
      "285/285 [==============================] - 14s 51ms/step - loss: 0.8404 - F1: 0.6979 - val_loss: 1.2006 - val_F1: 0.5328\n",
      "Epoch 25/50\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 0.8184 - F1: 0.7074 - val_loss: 1.2051 - val_F1: 0.5320\n",
      "Epoch 26/50\n",
      "285/285 [==============================] - 14s 50ms/step - loss: 0.8004 - F1: 0.7154 - val_loss: 1.2001 - val_F1: 0.5340\n",
      "Epoch 27/50\n",
      "285/285 [==============================] - 14s 50ms/step - loss: 0.7806 - F1: 0.7240 - val_loss: 1.2170 - val_F1: 0.5285\n",
      "Epoch 28/50\n",
      "285/285 [==============================] - 14s 50ms/step - loss: 0.7665 - F1: 0.7297 - val_loss: 1.2043 - val_F1: 0.5323\n",
      "Epoch 29/50\n",
      "285/285 [==============================] - 14s 51ms/step - loss: 0.7461 - F1: 0.7384 - val_loss: 1.2272 - val_F1: 0.5277\n",
      "Epoch 30/50\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 0.7334 - F1: 0.7439 - val_loss: 1.2210 - val_F1: 0.5255\n",
      "Epoch 31/50\n",
      "285/285 [==============================] - 15s 53ms/step - loss: 0.7183 - F1: 0.7502 - val_loss: 1.2489 - val_F1: 0.5196\n",
      "Epoch 32/50\n",
      "285/285 [==============================] - 15s 53ms/step - loss: 0.7038 - F1: 0.7564 - val_loss: 1.2313 - val_F1: 0.5251\n",
      "Epoch 33/50\n",
      "285/285 [==============================] - 15s 54ms/step - loss: 0.6920 - F1: 0.7614 - val_loss: 1.2139 - val_F1: 0.5287\n",
      "Epoch 34/50\n",
      "285/285 [==============================] - 15s 54ms/step - loss: 0.6768 - F1: 0.7676 - val_loss: 1.2397 - val_F1: 0.5232\n",
      "Epoch 35/50\n",
      "285/285 [==============================] - 15s 53ms/step - loss: 0.6668 - F1: 0.7714 - val_loss: 1.2327 - val_F1: 0.5251\n",
      "Epoch 36/50\n",
      "285/285 [==============================] - 15s 53ms/step - loss: 0.6558 - F1: 0.7761 - val_loss: 1.2394 - val_F1: 0.5233\n",
      "Epoch 37/50\n",
      "285/285 [==============================] - 15s 53ms/step - loss: 0.6463 - F1: 0.7799 - val_loss: 1.2558 - val_F1: 0.5166\n",
      "Epoch 38/50\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.6314 - F1: 0.7859 - val_loss: 1.2360 - val_F1: 0.5221\n",
      "Epoch 39/50\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.6213 - F1: 0.7899 - val_loss: 1.2301 - val_F1: 0.5246\n",
      "Epoch 40/50\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.6138 - F1: 0.7928 - val_loss: 1.2401 - val_F1: 0.5201\n",
      "Epoch 41/50\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.6041 - F1: 0.7968 - val_loss: 1.2460 - val_F1: 0.5177\n",
      "Epoch 42/50\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.5938 - F1: 0.8007 - val_loss: 1.2397 - val_F1: 0.5214\n",
      "Epoch 43/50\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.5870 - F1: 0.8034 - val_loss: 1.2430 - val_F1: 0.5269\n",
      "Epoch 44/50\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 0.5794 - F1: 0.8066 - val_loss: 1.2617 - val_F1: 0.5166\n",
      "Epoch 45/50\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.5699 - F1: 0.8101 - val_loss: 1.2398 - val_F1: 0.5240\n",
      "Epoch 46/50\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.5626 - F1: 0.8129 - val_loss: 1.2523 - val_F1: 0.5224\n",
      "Epoch 47/50\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.5552 - F1: 0.8158 - val_loss: 1.2469 - val_F1: 0.5198\n",
      "Epoch 48/50\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.5497 - F1: 0.8178 - val_loss: 1.2577 - val_F1: 0.5189\n",
      "Epoch 49/50\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.5408 - F1: 0.8212 - val_loss: 1.2523 - val_F1: 0.5202\n",
      "Epoch 50/50\n",
      "285/285 [==============================] - 14s 50ms/step - loss: 0.5364 - F1: 0.8230 - val_loss: 1.2536 - val_F1: 0.5192\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train, validation_data=(X_val, Y_val), batch_size=32,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HPCL\\anaconda3\\envs\\torch_env\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save('Deepwatermap_github_landsat+sentinel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Metrics #######################\n",
    "def IoU_pr_rec_f1(y_true, y_pred):\n",
    "    \n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    y_pred = ((y_pred)*1.).astype('float32')\n",
    "    \n",
    "    tp = np.sum(y_true*(y_pred))\n",
    "    tn = np.sum((1-y_true)*((1-y_pred)))\n",
    "    fp = np.sum((1-y_true)*(y_pred))\n",
    "    fn = np.sum((y_true)*((1-y_pred)))\n",
    "    \n",
    "    pr  = (tp/(tp+fp))\n",
    "    rec = (tp/(tp+fn))\n",
    "    f1  = ((2*pr*rec)/(pr+rec))\n",
    "    tnr = (tn/(tn+fp))\n",
    "    fpr = (fp/(fp+tn))\n",
    "    \n",
    "    intersection = y_true*y_pred\n",
    "    not_true     = 1 - y_true\n",
    "    union        = y_true + (not_true * y_pred)\n",
    "    iou         = (np.sum(intersection)) / (np.sum(union))\n",
    "    \n",
    "    return iou, pr, rec, f1, tnr, fpr\n",
    "\n",
    "# Saving Metrics\n",
    "def metrics():\n",
    "    x = np.arange(0,1,0.05)\n",
    "    IoU_      = []\n",
    "    threshold = []\n",
    "    precision = []\n",
    "    recall    = []\n",
    "    F_score   = []\n",
    "    TNR       = []\n",
    "    FPR       = []\n",
    "    name_list = []\n",
    "\n",
    "    dict_1 = {'Threshold': threshold,\n",
    "              'Name':name_list,\n",
    "              'IoU':IoU_,\n",
    "              'Precision':precision,\n",
    "              'Recall':recall,\n",
    "              'F-Score':F_score,\n",
    "              'True Negative Rate':TNR,\n",
    "              'False Positive Rate':FPR}\n",
    "    return dict_1\n",
    "\n",
    "#calculate F-scores only\n",
    "#update other parameters after best f-socore is found\n",
    "#\n",
    "def best_f_score(name, test_masks, predictions) :\n",
    "    dict_1 = metrics()\n",
    "    outer = 0\n",
    "    best_f_score = 0\n",
    "    x = 0       \n",
    "    y = 1\n",
    "    delta = 0.05\n",
    "    while outer<3:\n",
    "        z = np.arange(x, y, delta)         #\n",
    "        for threshold in z:\n",
    "            iou,precision,recall,f_score,tnr,fpr = IoU_pr_rec_f1((test_masks), (predictions>threshold))\n",
    "            dict_1['IoU'].append(iou)\n",
    "            dict_1['Threshold'].append(threshold)\n",
    "            dict_1['Precision'].append(precision)\n",
    "            dict_1['Recall'].append(recall)\n",
    "            dict_1['F-Score'].append(f_score)\n",
    "            dict_1['True Negative Rate'].append(tnr)\n",
    "            dict_1['False Positive Rate'].append(fpr)\n",
    "            dict_1['Name'].append(name)\n",
    "            if f_score>best_f_score:\n",
    "                best_f_score = f_score\n",
    "                x = threshold\n",
    "            else:\n",
    "                pass\n",
    "        x-=     delta\n",
    "        y = x + delta\n",
    "        delta*= 0.1\n",
    "        outer+= 1\n",
    "        \n",
    "    return dict_1\n",
    "\n",
    "dict_1 = metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Name</th>\n",
       "      <th>IoU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Positive Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0900</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat+Sentinel</td>\n",
       "      <td>0.348317</td>\n",
       "      <td>0.503058</td>\n",
       "      <td>0.531037</td>\n",
       "      <td>0.516669</td>\n",
       "      <td>0.992747</td>\n",
       "      <td>0.007253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0900</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat+Sentinel</td>\n",
       "      <td>0.348317</td>\n",
       "      <td>0.503058</td>\n",
       "      <td>0.531037</td>\n",
       "      <td>0.516669</td>\n",
       "      <td>0.992747</td>\n",
       "      <td>0.007253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat+Sentinel</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.504736</td>\n",
       "      <td>0.529175</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.992821</td>\n",
       "      <td>0.007179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0895</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat+Sentinel</td>\n",
       "      <td>0.348313</td>\n",
       "      <td>0.502967</td>\n",
       "      <td>0.531130</td>\n",
       "      <td>0.516665</td>\n",
       "      <td>0.992743</td>\n",
       "      <td>0.007257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0885</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat+Sentinel</td>\n",
       "      <td>0.348307</td>\n",
       "      <td>0.502778</td>\n",
       "      <td>0.531325</td>\n",
       "      <td>0.516658</td>\n",
       "      <td>0.992735</td>\n",
       "      <td>0.007265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold                                        Name       IoU  \\\n",
       "40     0.0900  DWM Trained BCE 50 Epochs Landsat+Sentinel  0.348317   \n",
       "28     0.0900  DWM Trained BCE 50 Epochs Landsat+Sentinel  0.348317   \n",
       "2      0.1000  DWM Trained BCE 50 Epochs Landsat+Sentinel  0.348315   \n",
       "39     0.0895  DWM Trained BCE 50 Epochs Landsat+Sentinel  0.348313   \n",
       "37     0.0885  DWM Trained BCE 50 Epochs Landsat+Sentinel  0.348307   \n",
       "\n",
       "    Precision    Recall   F-Score  True Negative Rate  False Positive Rate  \n",
       "40   0.503058  0.531037  0.516669            0.992747             0.007253  \n",
       "28   0.503058  0.531037  0.516669            0.992747             0.007253  \n",
       "2    0.504736  0.529175  0.516667            0.992821             0.007179  \n",
       "39   0.502967  0.531130  0.516665            0.992743             0.007257  \n",
       "37   0.502778  0.531325  0.516658            0.992735             0.007265  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test).squeeze()\n",
    "dict_1 = best_f_score('DWM Trained BCE 50 Epochs Landsat+Sentinel', Y_test, predictions)\n",
    "df_rotate = pd.DataFrame(dict_1)\n",
    "df_rotate = df_rotate.sort_values(by=['F-Score'], ascending=False)\n",
    "AP = average_precision_score(Y_test.squeeze().reshape(-1), predictions.reshape(-1))\n",
    "df_rotate.to_csv(r'F-score DWM.csv', mode='a')\n",
    "df_rotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Name</th>\n",
       "      <th>IoU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Positive Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.1325</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat</td>\n",
       "      <td>0.382093</td>\n",
       "      <td>0.523876</td>\n",
       "      <td>0.585371</td>\n",
       "      <td>0.552919</td>\n",
       "      <td>0.994235</td>\n",
       "      <td>0.005765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.1320</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat</td>\n",
       "      <td>0.382085</td>\n",
       "      <td>0.523812</td>\n",
       "      <td>0.585434</td>\n",
       "      <td>0.552911</td>\n",
       "      <td>0.994233</td>\n",
       "      <td>0.005767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.1330</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat</td>\n",
       "      <td>0.382083</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>0.585286</td>\n",
       "      <td>0.552909</td>\n",
       "      <td>0.994237</td>\n",
       "      <td>0.005763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.1340</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat</td>\n",
       "      <td>0.382074</td>\n",
       "      <td>0.524032</td>\n",
       "      <td>0.585132</td>\n",
       "      <td>0.552899</td>\n",
       "      <td>0.994241</td>\n",
       "      <td>0.005759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.1345</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Landsat</td>\n",
       "      <td>0.382073</td>\n",
       "      <td>0.524086</td>\n",
       "      <td>0.585064</td>\n",
       "      <td>0.552898</td>\n",
       "      <td>0.994243</td>\n",
       "      <td>0.005757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold                               Name       IoU  Precision  \\\n",
       "35     0.1325  DWM Trained BCE 50 Epochs Landsat  0.382093   0.523876   \n",
       "34     0.1320  DWM Trained BCE 50 Epochs Landsat  0.382085   0.523812   \n",
       "36     0.1330  DWM Trained BCE 50 Epochs Landsat  0.382083   0.523926   \n",
       "38     0.1340  DWM Trained BCE 50 Epochs Landsat  0.382074   0.524032   \n",
       "39     0.1345  DWM Trained BCE 50 Epochs Landsat  0.382073   0.524086   \n",
       "\n",
       "      Recall   F-Score  True Negative Rate  False Positive Rate  \n",
       "35  0.585371  0.552919            0.994235             0.005765  \n",
       "34  0.585434  0.552911            0.994233             0.005767  \n",
       "36  0.585286  0.552909            0.994237             0.005763  \n",
       "38  0.585132  0.552899            0.994241             0.005759  \n",
       "39  0.585064  0.552898            0.994243             0.005757  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_L).squeeze()\n",
    "dict_1 = best_f_score('DWM Trained BCE 50 Epochs Landsat', Y_test_L, predictions)\n",
    "df_rotate = pd.DataFrame(dict_1)\n",
    "df_rotate = df_rotate.sort_values(by=['F-Score'], ascending=False)\n",
    "AP = average_precision_score(Y_test_L.squeeze().reshape(-1), predictions.reshape(-1))\n",
    "# df_rotate.to_csv(r'F-score DWM.csv', mode='a')\n",
    "df_rotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47970960266633156"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Name</th>\n",
       "      <th>IoU</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>True Negative Rate</th>\n",
       "      <th>False Positive Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0700</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.326485</td>\n",
       "      <td>0.488017</td>\n",
       "      <td>0.496569</td>\n",
       "      <td>0.492256</td>\n",
       "      <td>0.991271</td>\n",
       "      <td>0.008729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0700</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.326485</td>\n",
       "      <td>0.488017</td>\n",
       "      <td>0.496569</td>\n",
       "      <td>0.492256</td>\n",
       "      <td>0.991271</td>\n",
       "      <td>0.008729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0695</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.326483</td>\n",
       "      <td>0.487881</td>\n",
       "      <td>0.496706</td>\n",
       "      <td>0.492254</td>\n",
       "      <td>0.991264</td>\n",
       "      <td>0.008736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0750</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.326480</td>\n",
       "      <td>0.489168</td>\n",
       "      <td>0.495371</td>\n",
       "      <td>0.492250</td>\n",
       "      <td>0.991332</td>\n",
       "      <td>0.008668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0685</td>\n",
       "      <td>DWM Trained BCE 50 Epochs Sentinel</td>\n",
       "      <td>0.326453</td>\n",
       "      <td>0.487622</td>\n",
       "      <td>0.496904</td>\n",
       "      <td>0.492219</td>\n",
       "      <td>0.991251</td>\n",
       "      <td>0.008749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold                                Name       IoU  Precision  \\\n",
       "40     0.0700  DWM Trained BCE 50 Epochs Sentinel  0.326485   0.488017   \n",
       "24     0.0700  DWM Trained BCE 50 Epochs Sentinel  0.326485   0.488017   \n",
       "39     0.0695  DWM Trained BCE 50 Epochs Sentinel  0.326483   0.487881   \n",
       "25     0.0750  DWM Trained BCE 50 Epochs Sentinel  0.326480   0.489168   \n",
       "37     0.0685  DWM Trained BCE 50 Epochs Sentinel  0.326453   0.487622   \n",
       "\n",
       "      Recall   F-Score  True Negative Rate  False Positive Rate  \n",
       "40  0.496569  0.492256            0.991271             0.008729  \n",
       "24  0.496569  0.492256            0.991271             0.008729  \n",
       "39  0.496706  0.492254            0.991264             0.008736  \n",
       "25  0.495371  0.492250            0.991332             0.008668  \n",
       "37  0.496904  0.492219            0.991251             0.008749  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_S).squeeze()\n",
    "dict_1 = best_f_score('DWM Trained BCE 50 Epochs Sentinel', Y_test_S, predictions)\n",
    "df_rotate = pd.DataFrame(dict_1)\n",
    "df_rotate = df_rotate.sort_values(by=['F-Score'], ascending=False)\n",
    "AP = average_precision_score(Y_test_S.squeeze().reshape(-1), predictions.reshape(-1))\n",
    "# df_rotate.to_csv(r'F-score DWM.csv', mode='a')\n",
    "df_rotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41468884418691176"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4053, 128, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44037982422109323"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "644.844px",
    "left": "1567px",
    "right": "20px",
    "top": "120px",
    "width": "333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
